<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="zioBb4Ac5xjO7-IkGVs3Qnyfbu-5lW01M2wTphSvcWU" />













  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="哈~我不适合在白天工作~">
<meta property="og:type" content="website">
<meta property="og:title" content="Liam&#39;s Blog">
<meta property="og:url" content="https://asdf0982.github.io/page/2/index.html">
<meta property="og:site_name" content="Liam&#39;s Blog">
<meta property="og:description" content="哈~我不适合在白天工作~">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Liam&#39;s Blog">
<meta name="twitter:description" content="哈~我不适合在白天工作~">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"hide","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://asdf0982.github.io/page/2/"/>





  <title>Liam's Blog - Share the joy of coding.</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-99966000-1', 'auto');
  ga('send', 'pageview');
</script>












  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Liam's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">Share the joy of coding.</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/16/CS231n学习笔记-LSTM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/16/CS231n学习笔记-LSTM/" itemprop="url">CS231n学习笔记(LSTM)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-16T18:04:25+08:00">
                2017-06-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-16T21:34:15+08:00">
                2017-06-16
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作业: <a href="/2017/06/16/CS231n学习笔记-LSTM/LSTM_Captioning.ipynb" title="[LSTM_Captioning.ipynb]">[LSTM_Captioning.ipynb]</a><br>参考:<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external"><strong>Understanding LSTM Networks</strong></a>和<a href="http://www.jianshu.com/p/e46b1aa48886" target="_blank" rel="external"><strong>CS231n_assignment3</strong></a><br>在使用RNN时,时间(t)过大会导致前后的信息相关程度越来越小,最后出现梯度消失现象.而LSTM(Long Short-Term Memory Networks)就是为了解决这个<strong>长期依赖</strong>问题而被提出的.<br>LSTM的一般结构见下图. 和RNN一样，LSTM也是随着时间序列重复着一样的模块，只是LSTM的每个某块比RNN更加复杂，拥有四个层（3个门+1个记忆单元）。下图方框内上方的那条水平线，被称为胞元状态（cell state），LSTM通过门结构对记忆单元上的信息进行线性修改，保证了当时间序列变得很长的时候，前后信息的关联度不会衰减。<img src="/2017/06/16/CS231n学习笔记-LSTM/LSTM.png" alt="[LSTM]" title="[LSTM]"></p>
<ol>
<li>forget gate:根据上一个时刻输出的h_t-1和当前输入x_t,通过sigmoid控制得到f_t <img src="/2017/06/16/CS231n学习笔记-LSTM/forget_gate.png" alt="[forget gate]" title="[forget gate]"></li>
<li>Input gate:决定哪些值进行更新进cell state.<img src="/2017/06/16/CS231n学习笔记-LSTM/input_gate.png" alt="[input gate]" title="[input gate]"><br>对cell state进行更新<img src="/2017/06/16/CS231n学习笔记-LSTM/update.png" alt="[update cell state]" title="[update cell state]"></li>
<li>Output gate:<img src="/2017/06/16/CS231n学习笔记-LSTM/output_gate.png" alt="[output gate]" title="[output gate]"></li>
</ol>
<p>LSTM还有很多变体见参考<strong>CS231n_assignment3</strong></p>
<h2 id="LSTM-step-forward"><a href="#LSTM-step-forward" class="headerlink" title="LSTM: step forward"></a>LSTM: step forward</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">H = prev_h.shape[1]</div><div class="line">a = x.dot(Wx) + prev_h.dot(Wh) + b</div><div class="line">z_i = sigmoid(a[:,:H]) #input gate it</div><div class="line">z_f = sigmoid(a[:,H:2*H]) #forget gate ft</div><div class="line">z_o = sigmoid(a[:,2*H:3*H])#output gate ot</div><div class="line">z_g = np.tanh(a[:,3*H:]) #input gate Ct</div><div class="line">next_c = z_f * prev_c + z_i * z_g</div><div class="line">z_t = np.tanh(next_c)</div><div class="line">next_h = z_o * z_t</div><div class="line">cache = (z_i, z_f, z_o, z_g, z_t, prev_c, prev_h, Wx, Wh, x)</div></pre></td></tr></table></figure>
<h2 id="LSTM-step-backward"><a href="#LSTM-step-backward" class="headerlink" title="LSTM: step backward"></a>LSTM: step backward</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">H = dnext_h.shape[1]</div><div class="line">z_i, z_f, z_o, z_g, z_t, prev_c, prev_h, Wx, Wh, x = cache</div><div class="line"></div><div class="line">dz_o = z_t * dnext_h</div><div class="line">dc_t = z_o * (1 - z_t * z_t) * dnext_h + dnext_c</div><div class="line">dz_f = prev_c * dc_t</div><div class="line">dz_i = z_g * dc_t</div><div class="line">dprev_c = z_f * dc_t</div><div class="line">dz_g = z_i * dc_t</div><div class="line">  </div><div class="line">da_i = (1 - z_i) * z_i * dz_i</div><div class="line">da_f = (1 - z_f) * z_f * dz_f</div><div class="line">da_o = (1 - z_o) * z_o * dz_o</div><div class="line">da_g = (1 - z_g * z_g) * dz_g</div><div class="line">da = np.hstack((da_i, da_f, da_o, da_g))</div><div class="line"></div><div class="line">dWx = x.T.dot(da)</div><div class="line">dWh = prev_h.T.dot(da)</div><div class="line">  </div><div class="line">db = np.sum(da, axis = 0)</div><div class="line">dx = da.dot(Wx.T)</div><div class="line">dprev_h = da.dot(Wh.T)</div></pre></td></tr></table></figure>
<h2 id="LSTM-forward"><a href="#LSTM-forward" class="headerlink" title="LSTM: forward"></a>LSTM: forward</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">N, T, D = x.shape</div><div class="line">H = b.shape[0]/4</div><div class="line">h = np.zeros((N, T, H))</div><div class="line">cache = &#123;&#125;</div><div class="line">prev_h = h0</div><div class="line">prev_c = np.zeros((N, H))</div><div class="line">for t in range(T):</div><div class="line">  xt = x[:, t, :]</div><div class="line">  next_h, next_c, cache[t] = lstm_step_forward(xt, prev_h, prev_c, Wx, Wh, b)</div><div class="line">  prev_h = next_h</div><div class="line">  prev_c = next_c</div><div class="line">  h[:, t, :] = prev_h</div></pre></td></tr></table></figure>
<h2 id="LSTM-backward"><a href="#LSTM-backward" class="headerlink" title="LSTM: backward"></a>LSTM: backward</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">N, T, H = dh.shape</div><div class="line">z_i, z_f, z_o, z_g, z_t, prev_c, prev_h, Wx, Wh, x = cache[T-1]</div><div class="line">D = x.shape[1]</div><div class="line">  </div><div class="line">dprev_h = np.zeros((N, H))</div><div class="line">dprev_c = np.zeros((N, H))</div><div class="line">dx = np.zeros((N, T, D))</div><div class="line">dh0 = np.zeros((N, H))</div><div class="line">dWx= np.zeros((D, 4*H))</div><div class="line">dWh = np.zeros((H, 4*H))</div><div class="line">db = np.zeros((4*H,))</div><div class="line">  </div><div class="line">for t in range(T):</div><div class="line">  t = T-1-t</div><div class="line">  step_cache = cache[t]</div><div class="line">  dnext_h = dh[:,t,:] + dprev_h</div><div class="line">  dnext_c = dprev_c</div><div class="line">  dx[:,t,:], dprev_h, dprev_c, dWxt, dWht, dbt = lstm_step_backward(dnext_h, dnext_c, step_cache)</div><div class="line">  dWx, dWh, db = dWx+dWxt, dWh+dWht, db+dbt</div><div class="line">  </div><div class="line">dh0 = dprev_h</div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/14/CS231n学习笔记-RNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/14/CS231n学习笔记-RNN/" itemprop="url">CS231n学习笔记(RNN)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-14T16:18:19+08:00">
                2017-06-14
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-16T21:35:03+08:00">
                2017-06-16
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作业: <a href="/2017/06/14/CS231n学习笔记-RNN/RNN_Captioning.ipynb" title="[RNN_Captioning.ipynb]">[RNN_Captioning.ipynb]</a><br>数据集准备:打开datesets内的shell文件,找到url拖至迅雷里下载至datasets并解压.<br>运行至第三个代码块时可能运行至<code>os.remove(fname)</code>报错.是因为文件缓存被python打开无法删除导致的,注释掉这句即可.<br><code>np.linspace</code>在指定的间隔内返回均匀间隔的数字.</p>
<h2 id="Vanilla-RNN-step-forward"><a href="#Vanilla-RNN-step-forward" class="headerlink" title="Vanilla RNN: step forward"></a>Vanilla RNN: step forward</h2><p>打开<code>cs231n/rnn_layers.py</code>找到<code>rnn_step_forward(x, prev_h, Wx, Wh, b)</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">a = prev_h.dot(Wh) + x.dot(Wx) + b</div><div class="line">next_h = np.tanh(a)</div><div class="line">cache = (x, prev_h, Wh, Wx, b, next_h)</div></pre></td></tr></table></figure></p>
<p>即next_h = tanh(x*Wx+pre_h*Wh+b)</p>
<h2 id="Vanilla-RNN-step-backward"><a href="#Vanilla-RNN-step-backward" class="headerlink" title="Vanilla RNN: step backward"></a>Vanilla RNN: step backward</h2><p>找到<code>rnn_step_backward(dnext_h, cache)</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">x, prev_h, Wh, Wx, b, next_h = cache</div><div class="line">da = dnext_h * (<span class="number">1</span> - next_h ** <span class="number">2</span>) <span class="comment">#(N,H)</span></div><div class="line">dx = np.dot(da, Wx.T) <span class="comment">#(N,D)</span></div><div class="line">dprev_h = np.dot(da, Wh.T) <span class="comment">#(N,H)</span></div><div class="line">dWx = np.dot(x.T, da) <span class="comment">#(D,H)</span></div><div class="line">dWh = np.dot(prev_h.T, da) <span class="comment">#(H,H)</span></div><div class="line">db = np.sum(da, axis = <span class="number">0</span>) <span class="comment">#(H,)</span></div></pre></td></tr></table></figure></p>
<p>若激活函数为sigmoid,那么$f’(z) = f(z)(1-f)$<br>若激活函数为tanh,那么$f’(z) = 1-(f(z))^2$</p>
<h2 id="Vanilla-RNN-forward"><a href="#Vanilla-RNN-forward" class="headerlink" title="Vanilla RNN: forward"></a>Vanilla RNN: forward</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">N, T, D = x.shape</div><div class="line">(H,) = b.shape</div><div class="line">h = np.zeros((N, T,H))</div><div class="line">prev_h = h0</div><div class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(T):</div><div class="line">  xt = x[:, t, :]</div><div class="line">  next_h,_ = rnn_step_forward(xt, prev_h, Wx, Wh, b)</div><div class="line">  prev_h = next_h</div><div class="line">  h[:, t, :] = prev_h</div><div class="line">cache = (x, h0, Wh, Wx, b, h)</div></pre></td></tr></table></figure>
<h2 id="Vanilla-RNN-backward"><a href="#Vanilla-RNN-backward" class="headerlink" title="Vanilla RNN: backward"></a>Vanilla RNN: backward</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">x, h0, Wh, Wx, b, h = cache</div><div class="line">N, T, H = dh.shape</div><div class="line">D = x.shape[<span class="number">2</span>]</div><div class="line">next_h = h[:, T<span class="number">-1</span>, :]</div><div class="line">dprev_h = np.zeros((N, H))</div><div class="line">dx = np.zeros((N, T, D))</div><div class="line">dh0 = np.zeros((N, H))</div><div class="line">dWx = np.zeros((D, H))</div><div class="line">dWh = np.zeros((H, H))</div><div class="line">db = np.zeros((H,))</div><div class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(T):</div><div class="line">  t = T<span class="number">-1</span>-t </div><div class="line">  xt = x[:, t, :] <span class="comment">#(N,D)</span></div><div class="line">  <span class="keyword">if</span> t==<span class="number">0</span>:</div><div class="line">    prev_h = h0</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    prev_h = h[:,t<span class="number">-1</span>,:]</div><div class="line">  step_cache = (xt, prev_h, Wh, Wx, b, next_h)</div><div class="line">  next_h = prev_h</div><div class="line">  dnext_h = dh[:, t, :] + dprev_h</div><div class="line">  dx[:, t, :], dprev_h, dWxt, dWht, dbt = rnn_step_backward(dnext_h, step_cache)</div><div class="line">  dWx, dWh, db = dWx+dWxt, dWh+dWht, db+dbt</div><div class="line">dh0 = dprev_h</div></pre></td></tr></table></figure>
<h2 id="Word-embedding-forward"><a href="#Word-embedding-forward" class="headerlink" title="Word embedding: forward"></a>Word embedding: forward</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">N, T = x.shape</div><div class="line">V, D = W.shape</div><div class="line">out = np.zeros((N, T, D))</div><div class="line">for i in range(N):</div><div class="line">  for j in range(T):</div><div class="line">    out[i, j] = W[x[i,j]]</div><div class="line">cache = (x, W.shape)</div></pre></td></tr></table></figure>
<p>词嵌入(word embedding)参考文章:<a href="http://licstar.net/archives/328" target="_blank" rel="external">Deep Learning in NLP （一）词向量和语言模型</a><br>这里W代表词典表有V个词, 每个词都用D维数组表示. 输入的x共有N句, 每句有T个词.<br>上面的代码就是将x里的词提出来,映射到W上.</p>
<h2 id="Word-embedding-backward"><a href="#Word-embedding-backward" class="headerlink" title="Word embedding: backward"></a>Word embedding: backward</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">x, W_shape = cache</div><div class="line">dW = np.zeros(W_shape)</div><div class="line">np.add.at(dW, x, dout)</div></pre></td></tr></table></figure>
<p>np.add.at表示dW在x的位置上,分别加上加上dout.例子如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; a = np.array([1, 2, 3, 4])</div><div class="line">&gt;&gt;&gt; np.add.at(a, [0, 1, 2, 2], 1)</div><div class="line">&gt;&gt;&gt; print(a)</div><div class="line">array([2, 3, 5, 4])</div><div class="line"></div><div class="line">&gt;&gt;&gt; a = np.array([1, 2, 3, 4])</div><div class="line">&gt;&gt;&gt; b = np.array([1, 2])</div><div class="line">&gt;&gt;&gt; np.add.at(a, [0, 1], b)</div><div class="line">&gt;&gt;&gt; print(a)</div><div class="line">array([2, 4, 3, 4])</div></pre></td></tr></table></figure></p>
<h2 id="CaptioningRNN-loss"><a href="#CaptioningRNN-loss" class="headerlink" title="CaptioningRNN.loss"></a>CaptioningRNN.loss</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">affine_out, affine_cache = affine_forward(features ,W_proj, b_proj)</div><div class="line">#(2)</div><div class="line">word_embedding_out, word_embedding_cache = word_embedding_forward(captions_in, W_embed)</div><div class="line">#(3)</div><div class="line">if self.cell_type == &apos;rnn&apos;:</div><div class="line">    rnn_or_lstm_out, rnn_cache = rnn_forward(word_embedding_out, affine_out, Wx, Wh, b)</div><div class="line">elif self.cell_type == &apos;lstm&apos;:</div><div class="line">    rnn_or_lstm_out, lstm_cache = lstm_forward(word_embedding_out, affine_out, Wx, Wh, b)</div><div class="line">else:</div><div class="line">    raise ValueError(&apos;Invalid cell_type &quot;%s&quot;&apos; % self.cell_type)</div><div class="line">#(4)</div><div class="line">temporal_affine_out, temporal_affine_cache = temporal_affine_forward(rnn_or_lstm_out, W_vocab, b_vocab)</div><div class="line">#(5)</div><div class="line">loss, dtemporal_affine_out = temporal_softmax_loss(temporal_affine_out, captions_out, mask)</div><div class="line">#(4)</div><div class="line">drnn_or_lstm_out, grads[&apos;W_vocab&apos;], grads[&apos;b_vocab&apos;] = temporal_affine_backward(dtemporal_affine_out, temporal_affine_cache)</div><div class="line">#(3)</div><div class="line">if self.cell_type == &apos;rnn&apos;:</div><div class="line">    dword_embedding_out, daffine_out, grads[&apos;Wx&apos;], grads[&apos;Wh&apos;], grads[&apos;b&apos;] = rnn_backward(drnn_or_lstm_out, rnn_cache)</div><div class="line">elif self.cell_type == &apos;lstm&apos;:</div><div class="line">    dword_embedding_out, daffine_out, grads[&apos;Wx&apos;], grads[&apos;Wh&apos;], grads[&apos;b&apos;] = lstm_backward(drnn_or_lstm_out, lstm_cache)</div><div class="line">else:</div><div class="line">    raise ValueError(&apos;Invalid cell_type &quot;%s&quot;&apos; % self.cell_type)</div><div class="line">#(2)</div><div class="line">grads[&apos;W_embed&apos;] = word_embedding_backward(dword_embedding_out, word_embedding_cache)</div><div class="line">#(1)</div><div class="line">dfeatures, grads[&apos;W_proj&apos;], grads[&apos;b_proj&apos;] = affine_backward(daffine_out, affine_cache)</div></pre></td></tr></table></figure>
<h2 id="CaptioningRNN-sample"><a href="#CaptioningRNN-sample" class="headerlink" title="CaptioningRNN.sample"></a>CaptioningRNN.sample</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">N, D = features.shape</div><div class="line">affine_out, affine_cache = affine_forward(features ,W_proj, b_proj)</div><div class="line"></div><div class="line">prev_word_idx = [self._start]*N</div><div class="line">prev_h = affine_out</div><div class="line">prev_c = np.zeros(prev_h.shape)</div><div class="line">captions[:,<span class="number">0</span>] = self._start</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,max_length):</div><div class="line">    prev_word_embed  = W_embed[prev_word_idx]</div><div class="line">    <span class="keyword">if</span> self.cell_type == <span class="string">'rnn'</span>:</div><div class="line">        next_h, rnn_step_cache = rnn_step_forward(prev_word_embed, prev_h, Wx, Wh, b)</div><div class="line">    <span class="keyword">elif</span> self.cell_type == <span class="string">'lstm'</span>:</div><div class="line">        next_h, next_c,lstm_step_cache = lstm_step_forward(prev_word_embed, prev_h, prev_c, Wx, Wh, b)</div><div class="line">        prev_c = next_c</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Invalid cell_type "%s"'</span> % self.cell_type)</div><div class="line">    vocab_affine_out, vocab_affine_out_cache = affine_forward(next_h, W_vocab, b_vocab)</div><div class="line">    captions[:,i] = list(np.argmax(vocab_affine_out, axis = <span class="number">1</span>))</div><div class="line">    prev_word_idx = captions[:,i]</div><div class="line">    prev_h = next_h</div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/13/PHPstorm10wamp3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/13/PHPstorm10wamp3/" itemprop="url">PHPstorm10+wamp3.0环境搭建</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-13T21:51:48+08:00">
                2017-06-13
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-13T23:13:09+08:00">
                2017-06-13
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>phpstorm10的破解过程和wamp的安装过程不展开讲了。<br>下面说说如何配置phpstorm。<br>第1步：wamp自带xDebug，找到php.ini，在末尾加入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">; XDEBUG Extension</div><div class="line"></div><div class="line">zend_extension_ts = &quot;D:/wamp64/bin/php/php5.6.25/zend_ext/php_xdebug-2.4.1-5.6-vc11-x86_64.dll&quot;</div><div class="line">;</div><div class="line">[xdebug]</div><div class="line">xdebug.remote_enable = off</div><div class="line">xdebug.profiler_enable = off</div><div class="line">xdebug.profiler_enable_trigger = off</div><div class="line">xdebug.profiler_output_name = cachegrind.out.%t.%p</div><div class="line">xdebug.profiler_output_dir = &quot;d:/wamp64/tmp&quot;</div><div class="line">xdebug.show_local_vars=0</div><div class="line">xdebug.idekey=PhpStorm</div><div class="line">xdebug.remote_enable = On</div><div class="line">xdebug.remote_host=localhost</div><div class="line">xdebug.remote_port=9000</div><div class="line">xdebug.remote_handler=dbgp</div></pre></td></tr></table></figure></p>
<p><em>注意</em>：其中.dll和tmp的路径根据实际情况修改。</p>
<p>第2步： File-&gt;Settings-&gt;Languages&amp;Frame Works-&gt;Php-&gt;Interpreter 选择web服务器套件中php.exe的路径<br><img src="/2017/06/13/PHPstorm10wamp3/2.png" alt="2.png" title=""><br>第3步： File-&gt;Settings-&gt;Languages&amp;Frame Works-&gt;Php-&gt;Servers 配置服务器相关设置:<br><img src="/2017/06/13/PHPstorm10wamp3/3.png" alt="3.png" title=""><br>第4步： File-&gt;Settings-&gt;Languages&amp;Frame Works-&gt;Php-&gt;Debug-&gt;DBGp Proxy 配置相关设置：<br><img src="/2017/06/13/PHPstorm10wamp3/4.png" alt="4.png" title=""><br>第5步： File-&gt;Settings-&gt;Languages&amp;Frame Works-&gt;Php-Debug 找到右边窗口对应的debug设置，把端口改成9000<br><img src="/2017/06/13/PHPstorm10wamp3/5.png" alt="5.png" title=""><br>第6步：在主界面右上角运行调试配置中创建phpwebapplication（我的php文件在www文件下的test下 所以设置为test）<br><img src="/2017/06/13/PHPstorm10wamp3/6.png" alt="6.png" title=""><br>第7步：安装chrome 扩展程序 —— xdebug helper 。点击phpstorm右上角的监听按钮。即可进行调试</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/11/CS231n学习笔记-TensorFlow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/11/CS231n学习笔记-TensorFlow/" itemprop="url">CS231n学习笔记(TensorFlow)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-11T00:27:32+08:00">
                2017-06-11
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-12T21:28:25+08:00">
                2017-06-12
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>完成作业: <a href="/2017/06/11/CS231n学习笔记-TensorFlow/TensorFlow.ipynb" title="[TensorFlow.ipynb]">[TensorFlow.ipynb]</a><br>跳过数据导入部分,直接进入model部分.<br>tensorflow的api有很多,建议边写边查.<a href="https://www.tensorflow.org/api_docs/python/tf/nn/max_pool" target="_blank" rel="external">api文档</a></p>
<h2 id="simple-model"><a href="#simple-model" class="headerlink" title="simple_model"></a>simple_model</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># clear old variables</span></div><div class="line">tf.reset_default_graph()</div><div class="line"></div><div class="line"><span class="comment"># setup input (e.g. the data that changes every batch)</span></div><div class="line"><span class="comment"># The first dim is None, and gets sets automatically based on batch size fed in</span></div><div class="line">X = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>])</div><div class="line">y = tf.placeholder(tf.int64, [<span class="keyword">None</span>])</div><div class="line">is_training = tf.placeholder(tf.bool)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">simple_model</span><span class="params">(X,y)</span>:</span></div><div class="line">    <span class="comment"># define our weights (e.g. init_two_layer_convnet)</span></div><div class="line">    </div><div class="line">    <span class="comment"># setup variables</span></div><div class="line">    Wconv1 = tf.get_variable(<span class="string">"Wconv1"</span>, shape=[<span class="number">7</span>, <span class="number">7</span>, <span class="number">3</span>, <span class="number">32</span>])</div><div class="line">    bconv1 = tf.get_variable(<span class="string">"bconv1"</span>, shape=[<span class="number">32</span>])</div><div class="line">    W1 = tf.get_variable(<span class="string">"W1"</span>, shape=[<span class="number">5408</span>, <span class="number">10</span>])</div><div class="line">    b1 = tf.get_variable(<span class="string">"b1"</span>, shape=[<span class="number">10</span>])</div><div class="line"></div><div class="line">    <span class="comment"># define our graph (e.g. two_layer_convnet)</span></div><div class="line">    a1 = tf.nn.conv2d(X, Wconv1, strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], padding=<span class="string">'VALID'</span>) + bconv1</div><div class="line">    h1 = tf.nn.relu(a1)</div><div class="line">    h1_flat = tf.reshape(h1,[<span class="number">-1</span>,<span class="number">5408</span>])</div><div class="line">    y_out = tf.matmul(h1_flat,W1) + b1</div><div class="line">    <span class="keyword">return</span> y_out</div><div class="line"></div><div class="line">y_out = simple_model(X,y)</div><div class="line"></div><div class="line"><span class="comment"># define our loss</span></div><div class="line">total_loss = tf.losses.hinge_loss(tf.one_hot(y,<span class="number">10</span>),logits=y_out)</div><div class="line">mean_loss = tf.reduce_mean(total_loss)</div><div class="line"></div><div class="line"><span class="comment"># define our optimizer</span></div><div class="line">optimizer = tf.train.AdamOptimizer(<span class="number">5e-4</span>) <span class="comment"># select optimizer and set learning rate</span></div><div class="line">train_step = optimizer.minimize(mean_loss)</div></pre></td></tr></table></figure>
<img src="/2017/06/11/CS231n学习笔记-TensorFlow/fliter.gif" alt="[回顾卷积过程]" title="[回顾卷积过程]">
<p><code>Wconv1 = tf.get_variable(&quot;Wconv1&quot;, shape=[7, 7, 3, 32])</code><br>表示卷积核的大小为7*7,每个卷积核包含3个通道,共有32个卷积核.</p>
<p><code>bconv1 = tf.get_variable(&quot;bconv1&quot;, shape=[32])</code><br>32个卷积核,每个都包含1个偏置项.</p>
<p><code>W1 = tf.get_variable(&quot;W1&quot;, shape=[5408, 10])</code><br>已知stride,图像与卷积核的宽度高度,根据公式’H_n = 1 + (H + 2 * pad - HH)/stride’计算卷积后输出矩阵的大小,1+(32-7)/2 = 13, 故每个卷积核会输出一个13*13的矩阵(不再以通道区分),共有32个卷积核,故输出的参数总数为13*13*32 = 5408. 而CASIA-10是最终分10类的,所以取10.</p>
<p><code>a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding=&#39;VALID&#39;) + bconv1</code></p>
<ul>
<li><a href="https://stackoverflow.com/questions/34619177/what-does-tf-nn-conv2d-do-in-tensorflow" target="_blank" rel="external">What does tf.nn.conv2d do in tensorflow?</a></li>
<li><a href="http://blog.csdn.net/lujiandong1/article/details/53728053" target="_blank" rel="external">tensorflow conv2d的padding解释以及参数解释</a><br>strides[0]和strides[3]必须为1.因为tensor的shape是<code>[batch, height, width, channels]</code>我们的stride只在中间两个中进行, 所以一般strides = [1, X, X, 1]</li>
</ul>
<p><code>total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)</code><br><a href="https://zhuanlan.zhihu.com/p/25896409" target="_blank" rel="external">tf.one_hot()使用</a>,即创建一个全零矩阵,将对应位置置1.</p>
<h2 id="Training-the-model-on-one-epoch"><a href="#Training-the-model-on-one-epoch" class="headerlink" title="Training the model on one epoch"></a>Training the model on one epoch</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_model</span><span class="params">(session, predict, loss_val, Xd, yd,</span></span></div><div class="line">              epochs=<span class="number">1</span>, batch_size=<span class="number">64</span>, print_every=<span class="number">100</span>,</div><div class="line">              training=None, plot_losses=False):</div><div class="line">    <span class="comment"># have tensorflow compute accuracy</span></div><div class="line">    correct_prediction = tf.equal(tf.argmax(predict,<span class="number">1</span>), y)</div><div class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div><div class="line">    </div><div class="line">    <span class="comment"># shuffle indicies</span></div><div class="line">    train_indicies = np.arange(Xd.shape[<span class="number">0</span>])</div><div class="line">    np.random.shuffle(train_indicies)</div><div class="line"></div><div class="line">    training_now = training <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="comment">#True</span></div><div class="line">    </div><div class="line">    <span class="comment"># setting up variables we want to compute (and optimizing)</span></div><div class="line">    <span class="comment"># if we have a training function, add that to things we compute</span></div><div class="line">    variables = [mean_loss,correct_prediction,accuracy]</div><div class="line">    <span class="keyword">if</span> training_now:</div><div class="line">        variables[<span class="number">-1</span>] = training</div><div class="line">    </div><div class="line">    <span class="comment"># counter </span></div><div class="line">    iter_cnt = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</div><div class="line">        <span class="comment"># keep track of losses and accuracy</span></div><div class="line">        correct = <span class="number">0</span></div><div class="line">        losses = []</div><div class="line">        <span class="comment"># make sure we iterate over the dataset once</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(int(math.ceil(Xd.shape[<span class="number">0</span>]/batch_size))):<span class="comment">#也许最后还有一些训练集没有被纳入,也就不管它们了,宁缺毋滥</span></div><div class="line">            <span class="comment"># generate indicies for the batch</span></div><div class="line">            start_idx = (i*batch_size)%Xd.shape[<span class="number">0</span>] <span class="comment">#batch索引起始位置</span></div><div class="line">            idx = train_indicies[start_idx:start_idx+batch_size] <span class="comment">#一个batch所有索引(已打乱)</span></div><div class="line">            </div><div class="line">            <span class="comment"># create a feed dictionary for this batch</span></div><div class="line">            feed_dict = &#123;X: Xd[idx,:],</div><div class="line">                         y: yd[idx],</div><div class="line">                         is_training: training_now &#125;</div><div class="line">            <span class="comment"># get batch size</span></div><div class="line">            actual_batch_size = yd[idx].shape[<span class="number">0</span>]</div><div class="line">            </div><div class="line">            <span class="comment"># have tensorflow compute loss and correct predictions</span></div><div class="line">            <span class="comment"># and (if given) perform a training step</span></div><div class="line">            loss, corr, _ = session.run(variables,feed_dict=feed_dict)</div><div class="line">            </div><div class="line">            <span class="comment"># aggregate performance stats</span></div><div class="line">            losses.append(loss*actual_batch_size)</div><div class="line">            correct += np.sum(corr)</div><div class="line">            </div><div class="line">            <span class="comment"># print every now and then</span></div><div class="line">            <span class="keyword">if</span> training_now <span class="keyword">and</span> (iter_cnt % print_every) == <span class="number">0</span>:</div><div class="line">                print(<span class="string">"Iteration &#123;0&#125;: with minibatch training loss = &#123;1:.3g&#125; and accuracy of &#123;2:.2g&#125;"</span>\</div><div class="line">                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size)) <span class="comment">#.ng表示n位有效数字</span></div><div class="line">            iter_cnt += <span class="number">1</span></div><div class="line">        total_correct = correct/Xd.shape[<span class="number">0</span>]</div><div class="line">        total_loss = np.sum(losses)/Xd.shape[<span class="number">0</span>]</div><div class="line">        print(<span class="string">"Epoch &#123;2&#125;, Overall loss = &#123;0:.3g&#125; and accuracy of &#123;1:.3g&#125;"</span>\</div><div class="line">              .format(total_loss,total_correct,e+<span class="number">1</span>))</div><div class="line">        <span class="keyword">if</span> plot_losses:</div><div class="line">            plt.plot(losses)</div><div class="line">            plt.grid(<span class="keyword">True</span>)</div><div class="line">            plt.title(<span class="string">'Epoch &#123;&#125; Loss'</span>.format(e+<span class="number">1</span>))</div><div class="line">            plt.xlabel(<span class="string">'minibatch number'</span>)</div><div class="line">            plt.ylabel(<span class="string">'minibatch loss'</span>)</div><div class="line">            plt.show()</div><div class="line">    <span class="keyword">return</span> total_loss,total_correct</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    <span class="keyword">with</span> tf.device(<span class="string">"/cpu:0"</span>): <span class="comment">#"/cpu:0" or "/gpu:0" </span></div><div class="line">        sess.run(tf.global_variables_initializer())</div><div class="line">        print(<span class="string">'Training'</span>)</div><div class="line">        run_model(sess,y_out,mean_loss,X_train,y_train,<span class="number">1</span>,<span class="number">64</span>,<span class="number">100</span>,train_step,<span class="keyword">True</span>)</div><div class="line">        print(<span class="string">'Validation'</span>)</div><div class="line">        run_model(sess,y_out,mean_loss,X_val,y_val,<span class="number">1</span>,<span class="number">64</span>)</div></pre></td></tr></table></figure>
<p><code>correct_prediction = tf.equal(tf.argmax(predict,1), y)</code><br><code>tf.argmax</code>是一个非常有用的函数，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签，比如tf.argmax(predict,1)返回的是模型对于任一输入x预测到的标签值.<br><code>tf.equal</code>返回一个布尔数组,如<code>[True, False, True, True]</code></p>
<p><code>accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</code><br>可以使用<code>tf.cast()</code>函数将其转换为布尔值转换为[1, 0, 1, 1]，以方便准确率的计算.<br><code>tf.reduce_mean</code>可跨越维度的计算张量各元素的平均值.</p>
<p><code>np.random.shuffle(train_indicies)</code><br>以随机次序重组序列</p>
<h2 id="Training-a-specific-model"><a href="#Training-a-specific-model" class="headerlink" title="Training a specific model"></a>Training a specific model</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">def complex_model(X,y,is_training):</div><div class="line">    Wconv1 = tf.get_variable(&quot;Wconv1&quot;, shape=[7, 7, 3, 32])</div><div class="line">    bconv1 = tf.get_variable(&quot;bconv1&quot;, shape=[32])</div><div class="line">    W1 = tf.get_variable(&quot;W1&quot;, shape=[5408, 1024])</div><div class="line">    b1 = tf.get_variable(&quot;b1&quot;, shape=[1024])</div><div class="line">    W2 = tf.get_variable(&quot;W2&quot;, shape=[1024, 10])</div><div class="line">    b2 = tf.get_variable(&quot;b2&quot;, shape=[10])</div><div class="line"></div><div class="line">    # define our graph (e.g. two_layer_convnet)</div><div class="line">    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,1,1,1], padding=&apos;VALID&apos;) + bconv1</div><div class="line">    #print (a1.shape)</div><div class="line">    h1 = tf.nn.relu(a1)</div><div class="line">    h2 = tf.contrib.layers.batch_norm(h1, </div><div class="line">                                      center=True, scale=True, </div><div class="line">                                      is_training=True,</div><div class="line">                                      scope=&apos;bn&apos;)</div><div class="line">    pool1 = tf.layers.max_pooling2d(inputs=h2, pool_size=[2, 2], strides=2)</div><div class="line">    pool1_flat = tf.reshape(pool1,[-1,5408])</div><div class="line">    y_1 = tf.matmul(pool1_flat,W1) + b1</div><div class="line">    y_1_new = tf.nn.relu(y_1)</div><div class="line">    y_out = tf.matmul(y_1_new,W2) + b2</div><div class="line">    </div><div class="line">    return y_out</div></pre></td></tr></table></figure>
<p>经过conv层,a1.shape = [?,26,26,32],再经过maxpooling层,pool1_flat的参数个数为(26*26*32)/(2*2) = 5408</p>
<p><code>Train a great model on CIFAR-10!</code>部分的模型在最开始的文件里.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/10/install-tensorflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/10/install-tensorflow/" itemprop="url">Install tensorflow on Win10</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-10T10:30:18+08:00">
                2017-06-10
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-10T11:08:36+08:00">
                2017-06-10
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="install-anaconda3"><a href="#install-anaconda3" class="headerlink" title="install anaconda3"></a>install anaconda3</h2><p>I use Anaconda2 and my python version is 2.7, but tensorflow needs python3.5. So the first step is to build python2.7 and 3.5 coexistence environment.</p>
<ol>
<li>If you have already installed Anaconda2, you need download <a href="https://repo.continuum.io/archive/.winzip/" target="_blank" rel="external">Anaconda3.</a> (choose 4.2.0)</li>
<li>Install it and change install path to “D:\Anaconda2\envs\Anaconda3”(D:\Anaconda2 is your Anaconda2’s path)<img src="/2017/06/10/install-tensorflow/20151231222220973.jpg" alt="[change path]" title="[change path]"></li>
<li>Cancel the default check when installing the software.<img src="/2017/06/10/install-tensorflow/20151231222309050.jpg" alt="[cancel tick]" title="[cancel tick]"></li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># To activate this environment, use:</div><div class="line"># &gt; activate Anaconda3</div><div class="line">#</div><div class="line"># To deactivate this environment, use:</div><div class="line"># &gt; deactivate Anaconda3</div></pre></td></tr></table></figure>
</li>
</ol>
<p>you can <code>activate Anaconda3</code> and then <code>python</code> to check your python version.</p>
<h2 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h2><p>look at <a href="https://www.tensorflow.org/install/install_windows" target="_blank" rel="external">install_windows</a></p>
<ol>
<li><code>activate Anaconda3</code></li>
<li>update pip <code>(Anaconda3) D:\&gt;python -m pip install --upgrade pip</code></li>
<li><p>if your PC don’t hava a GPU </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(Anaconda3) D:\&gt;pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.1.0-cp35-cp35m-win_amd64.whl</div></pre></td></tr></table></figure>
</li>
<li><p>if you succeed, you can see </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Installing collected packages: numpy, six, werkzeug, setuptools, protobuf, wheel, tensorflow</div><div class="line">Successfully installed numpy-1.13.0 protobuf-3.3.0 setuptools-36.0.1 six-1.10.0 tensorflow-1.1.0 werkzeug-0.12.2 wheel-0.29.0</div></pre></td></tr></table></figure>
</li>
<li><p>Invoke python from your shell as follows:<br><code>$ python</code><br>Enter the following short program inside the python interactive shell:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import tensorflow as tf</div><div class="line">&gt;&gt;&gt; hello = tf.constant(&apos;Hello, TensorFlow!&apos;)</div><div class="line">&gt;&gt;&gt; sess = tf.Session()</div><div class="line">&gt;&gt;&gt; print(sess.run(hello))</div></pre></td></tr></table></figure>
</li>
</ol>
<p>If the system outputs the following, then you are ready to begin writing TensorFlow programs:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Hello, TensorFlow!</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/08/CS231n学习笔记-卷积网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/08/CS231n学习笔记-卷积网络/" itemprop="url">CS231n学习笔记(卷积网络)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-08T21:37:55+08:00">
                2017-06-08
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-09T23:31:11+08:00">
                2017-06-09
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>完成作业:</p>
<ul>
<li><a href="/2017/06/08/CS231n学习笔记-卷积网络/ConvolutionalNetworks.ipynb" title="[ConvolutionalNetworks.ipynb]">[ConvolutionalNetworks.ipynb]</a></li>
<li><a href="/2017/06/08/CS231n学习笔记-卷积网络/cnn.py" title="[cnn.py]">[cnn.py]</a></li>
<li><a href="/2017/06/08/CS231n学习笔记-卷积网络/layers.py" title="[layers.py]">[layers.py]</a></li></ul>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/06/08/CS231n学习笔记-卷积网络/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/06/CS231n学习笔记（批量归一化）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/06/CS231n学习笔记（批量归一化）/" itemprop="url">CS231n学习笔记(批量归一化和dropout)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-06T21:20:53+08:00">
                2017-06-06
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-07T12:12:35+08:00">
                2017-06-07
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>引言大意：</p>
<blockquote>
<p>使深层网络更容易训练的一种方法是使用更复杂的优化程序，如SGD +momentum，RMSProp或Adam。 另一个策略是改变网络架构，使其更容易训练。这些方面的一个想法是最近提出的批量归一化(Batch normalization)这个想法比较简单。 当机器学习方法的输入数据由零均值和单位方差的不相关特征组成时，往往会更好地工作。 在训练神经网络时，我们可以在将数据馈送到网络之前对数据进行预处理，以明确地解耦其特征; 这将确保网络的第一层看到遵循良好分发的数据。 然而，即使我们对输入数据进行预处理，网络较深层的激活可能不会再去相关，并且不再具有零均值或单位方差，因为它们是从网络中较早的层输出的。 更糟糕的是，在训练过程中，网络每层的特征分布将随着每个层的权重更新而移动。<br></p></blockquote>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/06/06/CS231n学习笔记（批量归一化）/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/01/CS231n学习笔记-全连接网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/01/CS231n学习笔记-全连接网络/" itemprop="url">CS231n学习笔记(全连接网络)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-01T15:21:18+08:00">
                2017-06-01
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-04T20:21:39+08:00">
                2017-06-04
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>完成作业：</p>
<ul>
<li><a href="/2017/06/01/CS231n学习笔记-全连接网络/FullyConnectedNets.ipynb" title="[FullyConnectedNets.ipynb]">[FullyConnectedNets.ipynb]</a></li>
<li><a href="/2017/06/01/CS231n学习笔记-全连接网络/fc_net.py" title="[fc_net.py]">[fc_net.py]</a></li>
<li><a href="/2017/06/01/CS231n学习笔记-全连接网络/layers.py" title="[layers.py]">[layers.py]</a></li>
<li><a href="/2017/06/01/CS231n学习笔记-全连接网络/layer_utils.py" title="[layer_utils.py]">[layer_utils.py]</a></li>
<li><a href="/2017/06/01/CS231n学习笔记-全连接网络/optim.py" title="[optim.py]">[optim.py]</a>
</li>
</ul>
<p>这次作业非常重要，是assignment1的一次总结和大提升，我感觉应该反复咀嚼，琢磨透。<br></p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/06/01/CS231n学习笔记-全连接网络/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/05/31/Date型数据在SSM架构下的参数绑定与回显/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/05/31/Date型数据在SSM架构下的参数绑定与回显/" itemprop="url">Date型数据在SSM架构下的参数绑定与回显</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-31T18:23:09+08:00">
                2017-05-31
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-05-31T18:39:36+08:00">
                2017-05-31
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>Date型数据有很多种表现形式，传递起来相对来说比较复杂。最近做的项目涉及到这方面内容，做个笔记。</p>
<h2 id="Date型数据的参数绑定。"><a href="#Date型数据的参数绑定。" class="headerlink" title="Date型数据的参数绑定。"></a>Date型数据的参数绑定。</h2><p>想要将jsp页面收到String型参数转为Date型参数再保存到实体类中，首先需要<strong>创建一个转换器</strong>。<br>创建Controller包,姑且命名为liam.ssm.controller.converter。在其中创建一个类(Class),命名为CustomDateConverter.java<br></p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/05/31/Date型数据在SSM架构下的参数绑定与回显/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/05/29/CS231n学习笔记-两层网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/05/29/CS231n学习笔记-两层网络/" itemprop="url">CS231n学习笔记-两层网络</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-29T23:04:22+08:00">
                2017-05-29
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-05-30T16:51:56+08:00">
                2017-05-30
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>完成作业</p>
<ul>
<li><a href="/2017/05/29/CS231n学习笔记-两层网络/two_layer_net.ipynb" title="[two_layer_net.ipynb]">[two_layer_net.ipynb]</a></li>
<li><a href="/2017/05/29/CS231n学习笔记-两层网络/neural_net.py" title="[neural_net.py]">[neural_net.py]</a>
</li>
</ul>
<h2 id="前向传播计算图像在各类下的分数"><a href="#前向传播计算图像在各类下的分数" class="headerlink" title="前向传播计算图像在各类下的分数"></a>前向传播计算图像在各类下的分数</h2><p>在neural_net.py下编辑loss函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">L1 = ReLU(np.dot(X,W1)+b1)</div><div class="line">L2 = np.dot(L1,W2)+b2 <span class="comment"># N,C</span></div><div class="line">scores = L2</div></pre></td></tr></table></figure></p>
<p>L1代表第一层，使用ReLU作为激活函数。而ReLU函数没有定义，所以需要在TwoLayerNet外建一个。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ReLU</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.maximum(<span class="number">0</span>,x) <span class="comment"># f(z) = max(0, z)</span></div></pre></td></tr></table></figure></p>
<p>.ipynb文件中预置了正确答案，可以进行比对。我的如下：<br></p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/05/29/CS231n学习笔记-两层网络/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar2.jpg"
               alt="Liam Wang" />
          <p class="site-author-name" itemprop="name">Liam Wang</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">27</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/asdf0982" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/ghat0982" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liam Wang</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (search_path.endsWith("json")) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
