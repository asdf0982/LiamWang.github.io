<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="zioBb4Ac5xjO7-IkGVs3Qnyfbu-5lW01M2wTphSvcWU" />













  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="哈~我不适合在白天工作~">
<meta property="og:type" content="website">
<meta property="og:title" content="Liam&#39;s Blog">
<meta property="og:url" content="https://asdf0982.github.io/index.html">
<meta property="og:site_name" content="Liam&#39;s Blog">
<meta property="og:description" content="哈~我不适合在白天工作~">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Liam&#39;s Blog">
<meta name="twitter:description" content="哈~我不适合在白天工作~">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"hide","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://asdf0982.github.io/"/>





  <title>Liam's Blog - Share the joy of coding.</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-99966000-1', 'auto');
  ga('send', 'pageview');
</script>












  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Liam's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">Share the joy of coding.</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/08/14/TipsInDL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/14/TipsInDL/" itemprop="url">深度学习调参技巧</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-14T19:31:26+08:00">
                2017-08-14
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-08-14T22:01:42+08:00">
                2017-08-14
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>持续更新…</p>
<h2 id="扩大数据集"><a href="#扩大数据集" class="headerlink" title="扩大数据集"></a>扩大数据集</h2><p>常用的方法有将图像水平翻转, 随机剪裁,fancy PCA等.<br><a href="http://blog.csdn.net/u010555688/article/details/60757932" target="_blank" rel="external">data augmentation 数据增强方法总结</a><br>如在caffe的prototxt中加上<code>mirror</code> <code>crop_size</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: &quot;data&quot;</div><div class="line">  type: &quot;Data&quot;</div><div class="line">  top: &quot;data&quot;</div><div class="line">  top: &quot;label&quot;</div><div class="line">  include &#123;</div><div class="line">    phase: TRAIN</div><div class="line">  &#125;</div><div class="line">  transform_param &#123;</div><div class="line">    mirror: true</div><div class="line">    crop_size: 224</div><div class="line">    mean_value: 123.0</div><div class="line">    mean_value: 123.0</div><div class="line">    mean_value: 123.0</div><div class="line">  &#125;</div><div class="line">  data_param &#123;</div><div class="line">    source: &quot;examples/****/train_lmdb&quot;</div><div class="line">    batch_size: 8</div><div class="line">    backend: LMDB</div><div class="line">  &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h2><ol>
<li>零均值+归一化</li>
<li>PCA白化<br><a href="http://blog.csdn.net/danieljianfeng/article/details/42147109" target="_blank" rel="external">白化（Whitening） PCA白化 ZCA白化</a></li>
</ol>
<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><h3 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h3><ol>
<li>推荐从0.1开始向下调整学习率.当感觉loss不再下降时,可以将当前学习率除以2/5/10继续训练,看看loss是否继续降.</li>
<li>如果遇到loss一直上涨的情况,可能遇到了梯度过大的问题. 在caffe的solver中可以设置<code>clip_gradients</code>来抑制梯度.</li>
</ol>
<h3 id="在公开模型的基础上继续训练"><a href="#在公开模型的基础上继续训练" class="headerlink" title="在公开模型的基础上继续训练"></a>在公开模型的基础上继续训练</h3><p>可以从<a href="https://github.com/BVLC/caffe/wiki/Model-Zoo" target="_blank" rel="external">Caffe Model Zoo</a>下载模型,新增层继续训练,节约时间.</p>
<h3 id="从loss曲线中得到信息"><a href="#从loss曲线中得到信息" class="headerlink" title="从loss曲线中得到信息"></a>从loss曲线中得到信息</h3><img src="/2017/08/14/TipsInDL/2.png" alt="[tips]" title="[tips]">
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>现常用ReLU. 可以考虑换成PReLU</p>
<h2 id="正则化与随机失活"><a href="#正则化与随机失活" class="headerlink" title="正则化与随机失活"></a>正则化与随机失活</h2><p><a href="http://blog.csdn.net/u012162613/article/details/44261657" target="_blank" rel="external">正则化方法：L1和L2 regularization、数据集扩增、dropout</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/07/06/Factorized-Bilinear/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/06/Factorized-Bilinear/" itemprop="url">Factorized Bilinear Models for Image Recognition 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-06T16:58:44+08:00">
                2017-07-06
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-07-21T13:17:32+08:00">
                2017-07-21
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>关于细粒度(fine-grained), 还记得CIFAR-10数据集吗?里面有卡车, 飞机等10个截然不同的类别.这是用于传统的区分, 而细粒度就是如CUB鸟类数据集, 里面都是鸟,不过包含了不同的种类. 对这些看似相同实际不同种类的图像进行区分,就是细粒度区分.<br>主要做了这些事:</p>
<ol>
<li>提出了Factorized Bilinear layer来增强CNN层的能力,并使它更好的并入卷积和全链接层.</li>
<li>为了解决过拟合问题, 提出了DropFactor的正则化(regularization)方法.</li>
</ol>
<h2 id="回顾Bilinear-Pooling"><a href="#回顾Bilinear-Pooling" class="headerlink" title="回顾Bilinear Pooling"></a>回顾Bilinear Pooling</h2><p>也就是回顾[Bilinear CNN Models for Fine-grained Visual Recognition]这篇论文.<br><img src="/2017/07/06/Factorized-Bilinear/BilinearPooling.png" alt="[BilinearPooling]" title="[BilinearPooling]"><br>输入特征的大小是(h,w,n), 一般情况下h,w比较小,n比较大, 表现为一个长方体. 那么这里的$x_i$, 就是长方体中的一条(1,1,n).<br>当然以上都是我的假设,因为最终z的大小为(n,n)所以$x_i$的大小实际上是(n,1).<br>在之后的全链接层, y=b+Wz, z原本是一个(n,n)的矩阵被拉成了$(n^2,1)$的向量.<br>合并上面的两个式子<img src="/2017/07/06/Factorized-Bilinear/BL.png" alt="[合并]" title="[合并]"><br>看到xWx的格式这两个x就代表了(双线性)bilinear的意义,  实验也证明双线性的方法在细粒度领域是有效的.<br>同时我们也观察到Bilinear Pooling有大量的参数和很高的计算负担.并且参数过多容易导致过拟合,需要适当调整.</p>
<h2 id="Factorized-Bilinear-model"><a href="#Factorized-Bilinear-model" class="headerlink" title="Factorized Bilinear model"></a>Factorized Bilinear model</h2><p>基于上述的模型的优缺点,提出了FB模型.<br><img src="/2017/07/06/Factorized-Bilinear/FB.png" alt="[Factorized Bilinear]" title="[Factorized Bilinear]"><br><strong>其实就是将原本xWx(W的大小为NN)的部分改为了xFFx(F的大小为KN).</strong><br>疑惑:<br><del>1. 这里的$x_i$有n个,不知道这个n和上述的bilibearpooling的n维是不是同一个意思.(应该不是.)</del><br><del>2. $(f_i,f_j)$是什么?</del></p>
<p>反向传播时算法的梯度公式:<br><img src="/2017/07/06/Factorized-Bilinear/BP.png" alt="[back-propagating]" title="[back-propagating]"><br>计算复杂度:O(kn)</p>
<h2 id="DropFactor"><a href="#DropFactor" class="headerlink" title="DropFactor"></a>DropFactor</h2><img src="/2017/07/06/Factorized-Bilinear/DF.png" alt="[DropFactor]" title="[DropFactor]">
<p>(a)图不使用DropFactor,所有路径都要跑(注意共1+k条)所以为了防止过拟合,引入公式:<br><img src="/2017/07/06/Factorized-Bilinear/DF2.png" alt="DF2.png" title=""><br>疑惑:</p>
<ol>
<li>$m_j$ ~ Bernoulli(p)中间的符号</li>
<li>为什么测试时都乘以p?</li>
</ol>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><img src="/2017/07/06/Factorized-Bilinear/result.png" alt="[result]" title="[result]">
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/07/04/Kernel-Pooling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/04/Kernel-Pooling/" itemprop="url">Kernel Pooling for Convolutional Neural Networks 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-04T19:41:12+08:00">
                2017-07-04
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-07-21T13:23:08+08:00">
                2017-07-21
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>参考:</p>
<ul>
<li><a href="http://blog.csdn.net/losteng/article/details/51520555" target="_blank" rel="external">Global average Pooling</a></li>
<li>基础-<a href="http://blog.csdn.net/heyijia0327/article/details/38090229" target="_blank" rel="external">径向基(Radial basis function)神经网络、核函数的一些理解</a></li>
<li>进阶-<a href="http://www.cnblogs.com/zhangchaoyang/articles/2591663.html" target="_blank" rel="external">径向基函数（RBF）神经网络</a></li>
<li>DFT-<a href="https://zhuanlan.zhihu.com/p/19763358" target="_blank" rel="external">傅里叶分析之掐死教程</a></li>
<li>kernel SVM-<a href="http://blog.csdn.net/v_july_v/article/details/7624837" target="_blank" rel="external">支持向量机通俗导论（理解SVM的三层境界）</a></li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ol>
<li>提出了一种对特征映射的一般内核池化(kernel pooling)方法。 </li>
<li>提出的内核池化是可以区分的，可以与CNN进行联合优化。 </li>
</ol>
<h2 id="kernel"><a href="#kernel" class="headerlink" title="kernel"></a>kernel</h2><p>全连接层的参数太多,平均池化层又一刀切损失关键特征.怎么办啊!使用我们的Tayler系列核函数吧!<br>它可以近似高斯GBF.</p>
<h3 id="从张量中获得特征"><a href="#从张量中获得特征" class="headerlink" title="从张量中获得特征"></a>从张量中获得特征</h3><p>特征映射X一般有3个维度,h,w,c.<br>我们根据c将X表示为$\mathbf{x} = [x_1,x_2,…,x_c]^T$<br>论文提出Taylor series kernel来抽取特征.<br>首先定义2级张量:<br><img src="/2017/07/04/Kernel-Pooling/2Dtensor.png" alt="[2-level tensor]" title="[2-level tensor]"><br>也就是$xx^T$.<br>注: 当$x=(x_1,x_2),y=(y_1,y_2)$时,传统的内积$&lt;x,y&gt;=x^Ty=x_1y_1+x_2y_2$<br>如图为可视化的2级3级张量:<br><img src="/2017/07/04/Kernel-Pooling/123.png" alt="[tensor]" title="[tensor]"><br>引申出p级张量(p&gt;2):<br><img src="/2017/07/04/Kernel-Pooling/pDtensor.png" alt="[p-level tensor]" title="[p-level tensor]"><br>Taylor series kernel的公式为:<br><img src="/2017/07/04/Kernel-Pooling/Tkernel.png" alt="[Taylor series kernel]" title="[Taylor series kernel]"><br>将其表示为:$\kappa(\mathbf{x},\mathbf{y})=\phi(\mathbf{x})^T\phi(\mathbf{y})$<br>则<img src="/2017/07/04/Kernel-Pooling/X.png" alt="[taylor x]" title="[taylor x]"><br>其特征向量维度为:$\bigcirc(c^p)$ 所以即使c=512,p=3也有$10^8$.<br>因此需要一个近似方法.</p>
<h3 id="近似方法"><a href="#近似方法" class="headerlink" title="近似方法"></a>近似方法</h3><p>基于Tensor Sketching.</p>
<h4 id="Taylor-series-kernel"><a href="#Taylor-series-kernel" class="headerlink" title="Taylor series kernel"></a>Taylor series kernel</h4><img src="/2017/07/04/Kernel-Pooling/tsk.png" alt="[公式介绍]" title="[公式介绍]">
<p>算法的流程如下:<br><img src="/2017/07/04/Kernel-Pooling/A1.png" alt="[Algorithm 1]" title="[Algorithm 1]"><br>这样我们就把特征减少至$d=1+c+\sum_{i=2}^pd_i$<br>在实验中发现更高维度的特征有更好的近似,p越大错误越大,错误也和两个特征向量的夹角有关.</p>
<h4 id="Gaussian-RBF-kernel"><a href="#Gaussian-RBF-kernel" class="headerlink" title="Gaussian RBF kernel"></a>Gaussian RBF kernel</h4><p>使用Taylor series kernel 来近似Gaussian RBF.<br><img src="/2017/07/04/Kernel-Pooling/GS.png" alt="[Gaussian RBF kernel]" title="[Gaussian RBF kernel]"><br>p=4时最合适.<img src="/2017/07/04/Kernel-Pooling/GS1.png" alt="[Gaussian RBF & Tayler series with p]" title="[Gaussian RBF & Tayler series with p]"></p>
<h2 id="Learning-kernel-composition-end-to-end"><a href="#Learning-kernel-composition-end-to-end" class="headerlink" title="Learning kernel composition end-to-end"></a>Learning kernel composition end-to-end</h2><img src="/2017/07/04/Kernel-Pooling/F5.png" alt="[结构]" title="[结构]">
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/07/02/CS231n学习笔记-NetworkVisualization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/02/CS231n学习笔记-NetworkVisualization/" itemprop="url">CS231n学习笔记(NetworkVisualization-TensorFlow)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-02T21:13:48+08:00">
                2017-07-02
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-07-02T21:20:22+08:00">
                2017-07-02
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>完成的作业:<a href="/2017/07/02/CS231n学习笔记-NetworkVisualization/NetworkVisualization-TensorFlow.ipynb" title="[NetworkVisualization-TensorFlow.ipynb]">[NetworkVisualization-TensorFlow.ipynb]</a><br>这次作业探究了3种图像生成方法:</p>
<ol>
<li>Saliency Maps: 探究图像的哪些部分影响了网络的验证.</li>
<li>Fooling Images: 改变一张图像, 让它在你眼中看起来没什么变化, 但会被网络识别成目标的分类.</li>
<li>Class Visualization: 合成一张目标类别的图像.</li>
</ol>
<h2 id="预训练的模型"><a href="#预训练的模型" class="headerlink" title="预训练的模型"></a>预训练的模型</h2><p>采用SqueezeNet, 它可以在显著减少参数的情况下达到AlexNet的识别率. 在<code>cs231n/classifiers/squeezenet.py</code>看到网络模型代码.</p>
<h2 id="Saliency-Maps"><a href="#Saliency-Maps" class="headerlink" title="Saliency Maps"></a>Saliency Maps</h2><p>少量改变图像中的每一个像素, 网络分类器分数的变化情况就能反应该图像的重要性.<br>(本文的代码块相应的填入NetworkVisualization-TensorFlow.ipynb中)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">pass</div><div class="line">gradlossimg = tf.gradients(correct_scores, model.image)  </div><div class="line">tgradlossimg = gradlossimg[0]</div><div class="line">tsaliency = tf.reduce_max(tf.abs(tgradlossimg), 3)</div><div class="line">saliency = sess.run(tsaliency, feed_dict=&#123;model.image: X, model.labels: y&#125;)</div></pre></td></tr></table></figure></p>
<h2 id="Fooling-Images"><a href="#Fooling-Images" class="headerlink" title="Fooling Images"></a>Fooling Images</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">pass</div><div class="line">txf = tf.Variable(X_fooling)</div><div class="line">sess.run(tf.variables_initializer([txf]))</div><div class="line">targetclass_score =  tf.gather_nd(model.classifier, tf.stack((tf.range(X.shape[0]), model.labels), axis=1))</div><div class="line">g = tf.gradients(targetclass_score, model.image)[0]</div><div class="line">dX = learning_rate * g / tf.norm(g)</div><div class="line">txf = tf.assign_add(txf, dX)</div><div class="line">for _ in range(100):</div><div class="line">    X_fooling = sess.run(txf, feed_dict=&#123;model.image: X_fooling, model.labels:[target_y]&#125;)</div></pre></td></tr></table></figure>
<h2 id="Class-visualization"><a href="#Class-visualization" class="headerlink" title="Class visualization"></a>Class visualization</h2><p>$I$ 是图像, $y$ 目标类别, $s_y(I)$ 卷据网络关于 $I$ 在 $y$ 类上的分数.<br>$$<br>I^* = \arg\max_I s_y(I) - R(I)<br>$$<br>注意 $R(I)$ 在 argmax 中.<br>$<br>R(I) = \lambda |I|_2^2<br>$<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">loss = None # scalar loss</div><div class="line">grad = None # gradient of loss with respect to model.image, same size as model.image</div><div class="line">pass</div><div class="line">tloss = tf.gather_nd(model.classifier, tf.stack((tf.range(X.shape[0]), model.labels), axis=1))</div><div class="line">treg = l2_reg * tf.square(tf.norm(model.image))</div><div class="line"></div><div class="line">loss = tloss - treg</div><div class="line">grad = tf.gradients(loss, model.image)[0]</div><div class="line">grad_normalized = grad / tf.norm(grad)</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">pass</div><div class="line">dX_normalized = sess.run(grad_normalized, feed_dict=&#123;model.image: X, model.labels:[target_y]&#125;)                </div><div class="line">X += learning_rate * dX_normalized</div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/30/SphereFace/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/30/SphereFace/" itemprop="url">SphereFace:Deep Hypersphere Embedding for Face Recognition 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-30T10:51:27+08:00">
                2017-06-30
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-30T22:47:40+08:00">
                2017-06-30
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>先前的特征学习大多基于欧几里得边缘, 但是欧式边缘就适合那些学习到的具有判别力的特征吗? 本文就提出了一个组合的角度边缘来替代它.所设计的loss名为<em>A-Softmax loss</em>, 提取到的特征名为<em>SphereFace</em><br>本文主要有以下贡献:</p>
<ol>
<li>提出了A-Softmax loss来学习特征, 其原理在几何上能够解释.</li>
<li>导出参数m的下限, 使得A-Softmax loss能够让最小类间距离大于最大类内距离.</li>
</ol>
<h2 id="Deep-Hypersphere-Embedding"><a href="#Deep-Hypersphere-Embedding" class="headerlink" title="Deep Hypersphere Embedding"></a>Deep Hypersphere Embedding</h2><h3 id="回顾softmax-loss"><a href="#回顾softmax-loss" class="headerlink" title="回顾softmax loss"></a>回顾softmax loss</h3><p>在一个二分类问题中, softmax loss的决策边界(即正确类别的分数要比错误类别的分数要高, 其下限就是相等,也就是决策边界)是$(W_1-W_2)x+b_1-b_2=0$. 把$W^T_ix+b_i$写成$||W^T_i||||x||cos(\theta_i)+b_i$. <strong>其中$\theta_i$是$W_i$与$x$的夹角.</strong> 如果把W进行归一化($||W_i||=1$)把b置零($b_i=0$). 这样决策边界是$cos(\theta_1)-cos(\theta_2)=0$. 最后修改后的loss为:<br><img src="/2017/06/30/SphereFace/loss1.png" alt="[modified softmax loss]" title="[modified softmax loss]"><br>$y_i$是样本的标签, K是类的数量, j是[1,K]中的一个元素.</p>
<h3 id="向softmax引入角度边界"><a href="#向softmax引入角度边界" class="headerlink" title="向softmax引入角度边界"></a>向softmax引入角度边界</h3><p>我们都知道二分类问题的modified softmax loss需要$cos(\theta_1)&gt;cos(\theta_2)$,论文将其改为$cos(m\theta_1)&gt;cos(\theta_2)$.因为cos()在$(0,\pi)$中是递减的,所以当$m\geq2, \theta \in [0, \frac{\pi}{m} ]$时,$cos(\theta_1)&gt;cos(m\theta_1)$.所以这将让决策更严格,因为让$cos(\theta_1)$更小了但依然比$cos(\theta_2)$大.决策边界如图所示:<br><img src="/2017/06/30/SphereFace/boundary.png" alt="[二分类下的决策边界]" title="[二分类下的决策边界]"><br>然后把$cos(\theta_{y_i,i})$转化为$\psi(\theta_{y_i,i})$, 如图:<br><img src="/2017/06/30/SphereFace/A.png" alt="[A-softmax loss]" title="[A-softmax loss]"></p>
<h3 id="A-softmax的超球面解释"><a href="#A-softmax的超球面解释" class="headerlink" title="A-softmax的超球面解释"></a>A-softmax的超球面解释</h3><p>如图:<br><img src="/2017/06/30/SphereFace/sphere.png" alt="[loss的几何表达]" title="[loss的几何表达]"></p>
<h3 id="A-softmax的特性"><a href="#A-softmax的特性" class="headerlink" title="A-softmax的特性"></a>A-softmax的特性</h3><p>特性1. m越大越不好. 存在一个最小的m能让最大类内距离小于最小类间距离.<br>特性2. 在二分类问题中, $m_{min}\geq2+\sqrt3$. 文中给出证明.<br>特性3. 在多分类问题中, $m_{min}\geq3$. 文中给出证明.<br>基于以上,实验中使用$m=4$</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/28/CDL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/28/CDL/" itemprop="url">Coupled Deep Learning for Heterogeneous Face Recognition 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-28T23:48:54+08:00">
                2017-06-28
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-29T15:54:10+08:00">
                2017-06-29
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>不同模态(例如近红外NIR和可见光VIS)采集的人脸照片的匹配问题被称为异构人脸匹配(Heterogeneous face matching, HFM)问题. 不同模态的数据之间差异较大, 并且缺失足够的训练样本对.<br>本文提出一个深度学习网络, 名为CDL(coupled deep learning).致力于解决HFM问题.主要想法如下:</p>
<ol>
<li>提出一个组合迹范数(trace norm).它不但能加强不同模态之间(如VIS-NIR之间)的相关性, 而且可以约束参数空间, 特别是减轻在少量不成对的异质样本上的过拟合.</li>
<li>由于难以直接优化高阶组合迹范数(trace norm), 我们引入了其近似公式, 并提出了一种交互算法，以便在end-to-end CNN中有效优化。</li>
<li>使用一个基于跨模态三元组的跨模态排名采样方法(A cross-modal ranking sampling method defined on a set of cross-modal triplets)来最大化不同类别之间的差距. 此外, 它能有效的扩大训练数据并利用有限数量异质样本之间的信息.</li>
<li>在CASIA NIR-VIS 2.0面部数据库和三个素描照片数据库进行了广泛的实验评估, 表明所提出的方法提高了异构面部识别的最新性能。</li>
</ol>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="相关性约束"><a href="#相关性约束" class="headerlink" title="相关性约束"></a>相关性约束</h3><p>对CNN中的softmax loss引入相关性约束.<br>一般情况下,loss函数这么写.<br><img src="/2017/06/28/CDL/1.png" alt="[before]" title="[before]"><br>$X_i$表示抽出的特征.$W_i$表示网络中的参数.N和V表示NIR和VIS.<br>引入相关性约束后:<br><img src="/2017/06/28/CDL/2.png" alt="[after]" title="[after]"><br>$|| M ||_*$就表示迹范数(trace norm).是这样定义的:<br><img src="/2017/06/28/CDL/3.png" alt="[trace norm]" title="[trace norm]"><br>tr():表示矩阵的迹<br>inf():表示最大下界<br>$\Gamma$是一个半定矩阵.并由M得到.<br>将M引入公式,得到<br><img src="/2017/06/28/CDL/4.png" alt="[推导过程]" title="[推导过程]"><br>则反向传播中$W_N$和$W_V$的梯度:<br><img src="/2017/06/28/CDL/5.png" alt="[推导过程2]" title="[推导过程2]"><br>事实上这一步我也不懂.</p>
<h3 id="跨模态排名采样方法"><a href="#跨模态排名采样方法" class="headerlink" title="跨模态排名采样方法"></a>跨模态排名采样方法</h3><p>和triplet的思想类似,loss定义如下:<br><img src="/2017/06/28/CDL/6.png" alt="[Rank loss]" title="[Rank loss]"><br>在三元组中, a和n选自相同模态(如VIS)不同的类别, a和p选自相同的类别不同的模态.其约束如图:<br><img src="/2017/06/28/CDL/7.png" alt="[constraints]" title="[constraints]"></p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>使用light CNN作为基础网络.因为NIR-VIS的训练集很小, 先把网络在有大量VIS图片的数据集中训练, 然后用NIR-VIS微调.<br>在基础网络上修改,将上述的相关性约束和排名采样方法结合起来作为监督信号,如图:<br><img src="/2017/06/28/CDL/8.png" alt="[supervised signal]" title="[supervised signal]"><br>CDL的算法流程图:<br><img src="/2017/06/28/CDL/9.png" alt="[Algorithm 1]" title="[Algorithm 1]"></p>
<h2 id="疑问和思考"><a href="#疑问和思考" class="headerlink" title="疑问和思考"></a>疑问和思考</h2><p>线性代数部分的知识遗忘的比较厉害…</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/27/MTCNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/27/MTCNN/" itemprop="url">Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-27T19:28:41+08:00">
                2017-06-27
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-29T15:54:40+08:00">
                2017-06-29
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>参考:</p>
<ul>
<li><a href="http://blog.csdn.net/qq_14845119/article/details/52680940" target="_blank" rel="external">MTCNN（Multi-task convolutional neural networks）人脸对齐</a></li>
</ul>
<p>项目地址: <a href="https://github.com/kpzhang93/MTCNN_face_detection_alignment" target="_blank" rel="external">原版matlab</a>, <a href="https://github.com/DuinoDu/mtcnn" target="_blank" rel="external">python</a>, <a href="https://github.com/foreverYoungGitHub/MTCNN" target="_blank" rel="external">C++</a></p>
<h2 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h2><h3 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h3><p>整个方法如图所示:<br><img src="/2017/06/27/MTCNN/fig1.png" alt="[cascaded framework]" title="[cascaded framework]"><br>首先将一张图像调整至不同的大小来构建图像金字塔,作为下面操作的输入.</p>
<ol>
<li>通过一个名为P-Net的全由卷积层构建的网络获得候选的面部窗口和边界框回归向量.然后根据边界框回归向量对候选窗口进行校准, 并使用NMS合并高度重叠的候选窗口.</li>
<li>将候选窗口输入到另一个名为R-Net的CNN.它能拒绝掉大量的非人脸窗口.也需要用边界框回归向量校准和NMS.</li>
<li>与第二步类似,输入到一个名为O-Net的CNN中.但这一步用更多的监督来分辨人脸区域.最终输出5个面部基准点.</li>
</ol>
<h3 id="CNN结构"><a href="#CNN结构" class="headerlink" title="CNN结构"></a>CNN结构</h3><img src="/2017/06/27/MTCNN/fig2.png" alt="[The architectures]" title="[The architectures]">
<p>这一部分可以参考原版代码.<br>在卷积层后使用PReLU激活.</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>训练MTCNN包含3个部分, 人脸/非人脸分类器, 边界框回归和面部基准点定位。</p>
<ol>
<li>人脸分类:这是一个2分类问题.对于每一个样本$x_i$使用交叉熵计算loss.<img src="/2017/06/27/MTCNN/1.png" alt="[cross-entropy loss]" title="[cross-entropy loss]"></li>
<li>边界框回归:这是一个回归问题,使用欧式距离计算loss.(y有四个维度:左上角点的x,y,高度,宽度.下方公式前者是预测值,后者是实际值)</li>
<li>面部基准点定位:和边界框回归类似, 可看作回归问题, 也使用欧式距离计算loss.公式如上.(y表示基准点的坐标,共有5个点,故y有10维)</li>
<li>多资源训练:<img src="/2017/06/27/MTCNN/multi.png" alt="[目标函数]" title="[目标函数]"><br>N:训练样本数; $\alpha_j$:任务的重要程度. 在P-Net和R-Net使用(1, 0.5, 0.5)分配, 在O-Net使用(1, 0.5, 1)分配.$\beta$代表样本的标签.</li>
<li>线上的困难样本挖掘:在每个mini-batch中选出loss位于前70%的样本作为困难样本, 并且在BP阶段只利用这部分计算梯度.</li>
</ol>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>IoU表示与任何真实人脸的<strong>交并集</strong></p>
<ul>
<li>IoU&lt;0.3:非人脸(Negatives)</li>
<li>0.3&lt;IoU&lt;0.4:脸部基准点(landmarks)</li>
<li>0.4&lt;IoU&lt;0.65:部分人脸</li>
<li>IoU&gt;0.65:人脸</li>
</ul>
<p>训练集数据按以上划分方式,由3:1:1:2(非人脸:人脸:部分人脸:基准点)数据组成.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/27/center-loss/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/27/center-loss/" itemprop="url">A Discriminative Feature Learning Approach for Deep Face Recognition 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-27T12:34:20+08:00">
                2017-06-27
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-29T15:55:12+08:00">
                2017-06-29
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>发表于ECCV2016<br>项目地址: <a href="https://github.com/ydwen/caffe-face" target="_blank" rel="external">caffe</a>, <a href="https://github.com/pangyupo/mxnet_center_loss" target="_blank" rel="external">mxnet</a><br>参考:</p>
<ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;mid=2650325602&amp;idx=1&amp;sn=9bc6071bf62a4ccdde1df4b4c5ae39f4&amp;chksm=f235a568c5422c7ed7993b9d3b46bcd979d360605511284e4363a4a92f845019795569f8f3e9&amp;mpshare=1&amp;scene=1&amp;srcid=1028OCsg4y3EUMMTPjPzfrgo#rd" target="_blank" rel="external">【Technical Review】ECCV16 Center Loss及其在人脸识别中的应用</a></li>
<li><a href="http://www.jianshu.com/p/773fbd0b2472" target="_blank" rel="external">Center Loss - A Discriminative Feature Learning Approach for Deep Face Recognition 论文理解</a></li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>传统模型抽取出的深度特征比较分散, 是因为softmax loss仅仅区分数据.论文提出了一种新的损失函数center loss. 它可以让每个类学习一个特征中心, 减小类内的距离. 结合softmax loss就可以达到增大类间差异, 减小类内差异的效果.</p>
<h2 id="The-Proposed-Approach"><a href="#The-Proposed-Approach" class="headerlink" title="The Proposed Approach"></a>The Proposed Approach</h2><p>先用如下网络LeNet++训练MNIST数据集<br><img src="/2017/06/27/center-loss/LeNet.png" alt="[LeNet]" title="[LeNet]"><br>固定输出特征为2维,这样我们就可以在平面上看到结果.如图:<br><img src="/2017/06/27/center-loss/result1.png" alt="[softmax result]" title="[softmax result]"><br>结论: 虽然类间的差距已经明显, 但类内的差距依然较大.</p>
<h2 id="The-center-loss"><a href="#The-center-loss" class="headerlink" title="The center loss"></a>The center loss</h2><img src="/2017/06/27/center-loss/center_loss.png" alt="[center loss]" title="[center loss]">
<p>$c_{y_i}$代表$y_i$所在类的中心.<br>一次性将训练集的特征全部提取求出中心不现实, 论文中提出两个解决办法.</p>
<ol>
<li>在mini-batch中更新.</li>
<li>为了避免类别标错的图片使中心抖动, 使用$\alpha$来控制中心的学习率.见下下图Algorithm1-output-6</li>
</ol>
<p>center loss的梯度如下计算:<br><img src="/2017/06/27/center-loss/gradient.png" alt="[center loss gradient]" title="[center loss gradient]"><br>训练模型时将softmax loss与center loss结合, 设置$\lambda$来平衡两个loss函数.<br><img src="/2017/06/27/center-loss/step.png" alt="[step]" title="[step]"><br>不同的$\lambda$会带来不同的效果:<br><img src="/2017/06/27/center-loss/lambda.png" alt="[Different lambda]" title="[Different lambda]"><br>不同的λ对于特征的分布有很大的影响，合适的λ会提高网络的精确度。<br>center loss与contrastive loss,triplet loss相比, 不需要复杂的重建训练集,也不会造成数据戏剧性的大增.</p>
<p>实验部分见论文.注意激活函数使用了PReLU<br><img src="/2017/06/27/center-loss/prelu.png" alt="[ReLU & PReLU]" title="[ReLU & PReLU]"></p>
<h2 id="疑问和思考"><a href="#疑问和思考" class="headerlink" title="疑问和思考"></a>疑问和思考</h2><ol>
<li>为什么总loss不用(1-$\lambda$)a+$\lambda$b这样的形式?</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/26/GoogleNet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/26/GoogleNet/" itemprop="url">Going Deeper with Convolutions 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-26T18:50:47+08:00">
                2017-06-26
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-26T21:57:59+08:00">
                2017-06-26
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文由google发表于CVPR2015</p>
<h2 id="Introduction-amp-Related-Work"><a href="#Introduction-amp-Related-Work" class="headerlink" title="Introduction &amp; Related Work"></a>Introduction &amp; Related Work</h2><p>本文提出一个网络结构名为Inception. 它的特点是能提升对计算资源的使用效率.使得 在计算负担不变的情况下提升了网络的宽度和深度.它的前身GoogleNet(22层)在ILSVRC14中创下了验证和检测的记录.<br>GoogleNet借鉴了许多NIN的思想.其1x1的卷积核主要用于降维来解决计算瓶颈问题, 同时也能提高网络的深度和宽度.<br>检测(detection)方法来源于R-CNN.分两步:</p>
<ol>
<li>利用颜色, 文本等低层次的线索生成未知对象的位置提案.</li>
<li>在这些位置使用CNN分类器对物体进行检测.</li>
</ol>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>目前提升CNN性能的方法就是使网络变大变深. 但这也会增加计算的消耗, 并且容易导致过拟合. 增大的网络还会导致大量的计算资源被浪费.<br>解决这些问题的方法之一就是将全连接层改为稀疏连接层. 哪个结构用这个方法用的最好呢?对啦,就是我们的Inception结构.</p>
<h2 id="Architechture"><a href="#Architechture" class="headerlink" title="Architechture"></a>Architechture</h2><p>如图:<br><img src="/2017/06/26/GoogleNet/Inception.png" alt="[Inception module]" title="[Inception module]"><br>图片被多个大小的卷积核卷积, 提取出来的特征到下一层汇总.</p>
<h2 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h2><p>如图:<br><img src="/2017/06/26/GoogleNet/GoogleNet.png" alt="[GoogleNet]" title="[GoogleNet]"><br>可以参考阅读:<a href="https://github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/train_val.prototxt" target="_blank" rel="external">Caffe中GoogleNet的写法</a><br>#3x3 reduce代表3x3卷积前1x1滤波器的个数.<br>所有激活函数使用RELU.<br>第一个卷积层输出的计算为$\frac{224+2*3-7}{2}+1=112$(注意是向下取整)<br>第一个pool层输出的计算为$\frac{112-3}{2}+1$发现并不能整除.故一定自动补了padding.结果为56<br>inception(3a) 256 = 64(#1<em>1)+128(#3</em>3)+32(#5*5)+32(pool), 就是把各种方法得到的相同大小的结果拼接到一块输出.<br>使用avg pool层代替全连接层在top-1的准确率上获得了0.6%的提升.</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>采用<a href="http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf" target="_blank" rel="external">Large scale distributed deep networks</a>提到的分布置信网络(DistBelief). SGD+momentum的最优化方法, momentum=0.9, lr每8个epoch下降4%.详见论文.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/24/FaceNet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/24/FaceNet/" itemprop="url">FaceNet:A Unified Embedding for Face Recognition and Clustering 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-24T11:35:03+08:00">
                2017-06-24
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-24T22:55:04+08:00">
                2017-06-24
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文由GOOGLE于2015年发表在CVPR<br>参考:</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/24837264" target="_blank" rel="external">谷歌人脸识别系统FaceNet解析</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/46687471" target="_blank" rel="external">FaceNet–Google的人脸识别</a></li>
<li><a href="http://www.cnblogs.com/xiaohuahua108/p/6505756.html" target="_blank" rel="external">FaceNet—深度学习与人脸识别的二次结合</a></li>
</ul>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>本文提出一个系统名为FaceNet. 它可以直接将人脸图像映射至欧式空间, 其距离能直接反应出人脸间的相似度. 一旦生成该空间, 识别, 验证, 聚类等任务都可以用它来轻松完成. FaceNet在LFW上达到了99.63%的准确率, 在Youtube Faces DB达到95.12%.<br>和之前的方法(先输出高维度特征向量, 然后用PCA等降维, 再用分类器分类)不同, FaceNet直接使用基于triplets的LMNN（最大边界近邻分类）的loss函数训练神经网络, 网络直接输出为128维度的向量空间.<br>其人脸比对的结果如图所示:<br><img src="/2017/06/24/FaceNet/1.png" alt="[Illumination and Pose invariance]" title="[Illumination and Pose invariance]"><br>可以看到1.1就是阈值.</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>本文探索了2个网络.第一类为Zeiler&amp;Fergus研究中使用的神经网络, 受NIN影响, 我们在网络后面加了多个1*1*d卷积层, 第二类为Inception网络.<br>关键在于网络的末端使用了triplet loss作为目标函数. </p>
<h3 id="Triplet-Loss"><a href="#Triplet-Loss" class="headerlink" title="Triplet Loss"></a>Triplet Loss</h3><p>triplet loss: 在3个样本中,最小化类内差距,最大化类间差距.如图:<br><img src="/2017/06/24/FaceNet/triplet.png" alt="[Triplet Loss]" title="[Triplet Loss]"><br>公式如下:<br><img src="/2017/06/24/FaceNet/tripletloss.png" alt="[triplet loss公式]" title="[triplet loss公式]"></p>
<h3 id="Triplet-3个样本的选择"><a href="#Triplet-3个样本的选择" class="headerlink" title="Triplet 3个样本的选择"></a>Triplet 3个样本的选择</h3><p>我们想要从类内选择出一些P样本(hard-positive), 使他们与A样本的平均距离最大(argmax). 同时从类外选择出一些N样本(hard-negative), 使他们与A样本的平均距离最小(argmin). 但计算整个训练集之间的平均最大最小距离是不现实的.这里有两个办法解决它:</p>
<ol>
<li>每隔几步产生triplets, 计算它们在子数据集中的argmax和argmin. </li>
<li>在线产生triplets, 从mini-batch中得到hard positive/negative样本.(本文使用)</li>
</ol>
<p>文章选用方法2, 为了防止选择不当, 使用如下公式来约束样本选择.<br><img src="/2017/06/24/FaceNet/select.png" alt="[help to select]" title="[help to select]"></p>
<h3 id="深度卷积网络"><a href="#深度卷积网络" class="headerlink" title="深度卷积网络"></a>深度卷积网络</h3><p>第一个是Zeiler&amp;Fergus的22层网络.<br><img src="/2017/06/24/FaceNet/NN1.png" alt="[NN1]" title="[NN1]"><br>第二个网络<br><img src="/2017/06/24/FaceNet/NN2.png" alt="[NN2]" title="[NN2]"></p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ol>
<li>NN2(input 224*224)的效果最好.</li>
<li>即使图像只有80*80, 验证正确率下降的也不大.</li>
<li>NN1输出的特征在128维时效果最好.</li>
<li>训练的数据量增大能提高准确率.</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar2.jpg"
               alt="Liam Wang" />
          <p class="site-author-name" itemprop="name">Liam Wang</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">34</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/asdf0982" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/ghat0982" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://cockyyao.github.io/" title="CockyYao's Note" target="_blank">CockyYao's Note</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liam Wang</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (search_path.endsWith("json")) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
