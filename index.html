<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="zioBb4Ac5xjO7-IkGVs3Qnyfbu-5lW01M2wTphSvcWU" />













  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="哈~我不适合在白天工作~">
<meta property="og:type" content="website">
<meta property="og:title" content="Liam&#39;s Blog">
<meta property="og:url" content="https://asdf0982.github.io/index.html">
<meta property="og:site_name" content="Liam&#39;s Blog">
<meta property="og:description" content="哈~我不适合在白天工作~">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Liam&#39;s Blog">
<meta name="twitter:description" content="哈~我不适合在白天工作~">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"hide","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://asdf0982.github.io/"/>





  <title>Liam's Blog - Share the joy of coding.</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-99966000-1', 'auto');
  ga('send', 'pageview');
</script>












  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Liam's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">Share the joy of coding.</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/07/02/CS231n学习笔记-NetworkVisualization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/02/CS231n学习笔记-NetworkVisualization/" itemprop="url">CS231n学习笔记(NetworkVisualization-TensorFlow)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-02T21:13:48+08:00">
                2017-07-02
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-07-02T21:20:22+08:00">
                2017-07-02
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>完成的作业:<a href="/2017/07/02/CS231n学习笔记-NetworkVisualization/NetworkVisualization-TensorFlow.ipynb" title="[NetworkVisualization-TensorFlow.ipynb]">[NetworkVisualization-TensorFlow.ipynb]</a><br>这次作业探究了3种图像生成方法:</p>
<ol>
<li>Saliency Maps: 探究图像的哪些部分影响了网络的验证.</li>
<li>Fooling Images: 改变一张图像, 让它在你眼中看起来没什么变化, 但会被网络识别成目标的分类.</li>
<li>Class Visualization: 合成一张目标类别的图像.</li>
</ol>
<h2 id="预训练的模型"><a href="#预训练的模型" class="headerlink" title="预训练的模型"></a>预训练的模型</h2><p>采用SqueezeNet, 它可以在显著减少参数的情况下达到AlexNet的识别率. 在<code>cs231n/classifiers/squeezenet.py</code>看到网络模型代码.</p>
<h2 id="Saliency-Maps"><a href="#Saliency-Maps" class="headerlink" title="Saliency Maps"></a>Saliency Maps</h2><p>少量改变图像中的每一个像素, 网络分类器分数的变化情况就能反应该图像的重要性.<br>(本文的代码块相应的填入NetworkVisualization-TensorFlow.ipynb中)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">pass</div><div class="line">gradlossimg = tf.gradients(correct_scores, model.image)  </div><div class="line">tgradlossimg = gradlossimg[0]</div><div class="line">tsaliency = tf.reduce_max(tf.abs(tgradlossimg), 3)</div><div class="line">saliency = sess.run(tsaliency, feed_dict=&#123;model.image: X, model.labels: y&#125;)</div></pre></td></tr></table></figure></p>
<h2 id="Fooling-Images"><a href="#Fooling-Images" class="headerlink" title="Fooling Images"></a>Fooling Images</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">pass</div><div class="line">txf = tf.Variable(X_fooling)</div><div class="line">sess.run(tf.variables_initializer([txf]))</div><div class="line">targetclass_score =  tf.gather_nd(model.classifier, tf.stack((tf.range(X.shape[0]), model.labels), axis=1))</div><div class="line">g = tf.gradients(targetclass_score, model.image)[0]</div><div class="line">dX = learning_rate * g / tf.norm(g)</div><div class="line">txf = tf.assign_add(txf, dX)</div><div class="line">for _ in range(100):</div><div class="line">    X_fooling = sess.run(txf, feed_dict=&#123;model.image: X_fooling, model.labels:[target_y]&#125;)</div></pre></td></tr></table></figure>
<h2 id="Class-visualization"><a href="#Class-visualization" class="headerlink" title="Class visualization"></a>Class visualization</h2><p>$I$ 是图像, $y$ 目标类别, $s_y(I)$ 卷据网络关于 $I$ 在 $y$ 类上的分数.<br>$$<br>I^* = \arg\max_I s_y(I) - R(I)<br>$$<br>注意 $R(I)$ 在 argmax 中.<br>$<br>R(I) = \lambda |I|_2^2<br>$<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">loss = None # scalar loss</div><div class="line">grad = None # gradient of loss with respect to model.image, same size as model.image</div><div class="line">pass</div><div class="line">tloss = tf.gather_nd(model.classifier, tf.stack((tf.range(X.shape[0]), model.labels), axis=1))</div><div class="line">treg = l2_reg * tf.square(tf.norm(model.image))</div><div class="line"></div><div class="line">loss = tloss - treg</div><div class="line">grad = tf.gradients(loss, model.image)[0]</div><div class="line">grad_normalized = grad / tf.norm(grad)</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">pass</div><div class="line">dX_normalized = sess.run(grad_normalized, feed_dict=&#123;model.image: X, model.labels:[target_y]&#125;)                </div><div class="line">X += learning_rate * dX_normalized</div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/30/SphereFace/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/30/SphereFace/" itemprop="url">SphereFace:Deep Hypersphere Embedding for Face Recognition 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-30T10:51:27+08:00">
                2017-06-30
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-30T22:47:40+08:00">
                2017-06-30
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>先前的特征学习大多基于欧几里得边缘, 但是欧式边缘就适合那些学习到的具有判别力的特征吗? 本文就提出了一个组合的角度边缘来替代它.所设计的loss名为<em>A-Softmax loss</em>, 提取到的特征名为<em>SphereFace</em><br>本文主要有以下贡献:</p>
<ol>
<li>提出了A-Softmax loss来学习特征, 其原理在几何上能够解释.</li>
<li>导出参数m的下限, 使得A-Softmax loss能够让最小类间距离大于最大类内距离.</li>
</ol>
<h2 id="Deep-Hypersphere-Embedding"><a href="#Deep-Hypersphere-Embedding" class="headerlink" title="Deep Hypersphere Embedding"></a>Deep Hypersphere Embedding</h2><h3 id="回顾softmax-loss"><a href="#回顾softmax-loss" class="headerlink" title="回顾softmax loss"></a>回顾softmax loss</h3><p>在一个二分类问题中, softmax loss的决策边界(即正确类别的分数要比错误类别的分数要高, 其下限就是相等,也就是决策边界)是$(W_1-W_2)x+b_1-b_2=0$. 把$W^T_ix+b_i$写成$||W^T_i||||x||cos(\theta_i)+b_i$. <strong>其中$\theta_i$是$W_i$与$x$的夹角.</strong> 如果把W进行归一化($||W_i||=1$)把b置零($b_i=0$). 这样决策边界是$cos(\theta_1)-cos(\theta_2)=0$. 最后修改后的loss为:<br><img src="/2017/06/30/SphereFace/loss1.png" alt="[modified softmax loss]" title="[modified softmax loss]"><br>$y_i$是样本的标签, K是类的数量, j是[1,K]中的一个元素.</p>
<h3 id="向softmax引入角度边界"><a href="#向softmax引入角度边界" class="headerlink" title="向softmax引入角度边界"></a>向softmax引入角度边界</h3><p>我们都知道二分类问题的modified softmax loss需要$cos(\theta_1)&gt;cos(\theta_2)$,论文将其改为$cos(m\theta_1)&gt;cos(\theta_2)$.因为cos()在$(0,\pi)$中是递减的,所以当$m\geq2, \theta \in [0, \frac{\pi}{m} ]$时,$cos(\theta_1)&gt;cos(m\theta_1)$.所以这将让决策更严格,因为让$cos(\theta_1)$更小了但依然比$cos(\theta_2)$大.决策边界如图所示:<br><img src="/2017/06/30/SphereFace/boundary.png" alt="[二分类下的决策边界]" title="[二分类下的决策边界]"><br>然后把$cos(\theta_{y_i,i})$转化为$\psi(\theta_{y_i,i})$, 如图:<br><img src="/2017/06/30/SphereFace/A.png" alt="[A-softmax loss]" title="[A-softmax loss]"></p>
<h3 id="A-softmax的超球面解释"><a href="#A-softmax的超球面解释" class="headerlink" title="A-softmax的超球面解释"></a>A-softmax的超球面解释</h3><p>如图:<br><img src="/2017/06/30/SphereFace/sphere.png" alt="[loss的几何表达]" title="[loss的几何表达]"></p>
<h3 id="A-softmax的特性"><a href="#A-softmax的特性" class="headerlink" title="A-softmax的特性"></a>A-softmax的特性</h3><p>特性1. m越大越不好. 存在一个最小的m能让最大类内距离小于最小类间距离.<br>特性2. 在二分类问题中, $m_{min}\geq2+\sqrt3$. 文中给出证明.<br>特性3. 在多分类问题中, $m_{min}\geq3$. 文中给出证明.<br>基于以上,实验中使用$m=4$</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/28/CDL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/28/CDL/" itemprop="url">Coupled Deep Learning for Heterogeneous Face Recognition 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-28T23:48:54+08:00">
                2017-06-28
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-29T15:54:10+08:00">
                2017-06-29
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>不同模态(例如近红外NIR和可见光VIS)采集的人脸照片的匹配问题被称为异构人脸匹配(Heterogeneous face matching, HFM)问题. 不同模态的数据之间差异较大, 并且缺失足够的训练样本对.<br>本文提出一个深度学习网络, 名为CDL(coupled deep learning).致力于解决HFM问题.主要想法如下:</p>
<ol>
<li>提出一个组合迹范数(trace norm).它不但能加强不同模态之间(如VIS-NIR之间)的相关性, 而且可以约束参数空间, 特别是减轻在少量不成对的异质样本上的过拟合.</li>
<li>由于难以直接优化高阶组合迹范数(trace norm), 我们引入了其近似公式, 并提出了一种交互算法，以便在end-to-end CNN中有效优化。</li>
<li>使用一个基于跨模态三元组的跨模态排名采样方法(A cross-modal ranking sampling method defined on a set of cross-modal triplets)来最大化不同类别之间的差距. 此外, 它能有效的扩大训练数据并利用有限数量异质样本之间的信息.</li>
<li>在CASIA NIR-VIS 2.0面部数据库和三个素描照片数据库进行了广泛的实验评估, 表明所提出的方法提高了异构面部识别的最新性能。</li>
</ol>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="相关性约束"><a href="#相关性约束" class="headerlink" title="相关性约束"></a>相关性约束</h3><p>对CNN中的softmax loss引入相关性约束.<br>一般情况下,loss函数这么写.<br><img src="/2017/06/28/CDL/1.png" alt="[before]" title="[before]"><br>$X_i$表示抽出的特征.$W_i$表示网络中的参数.N和V表示NIR和VIS.<br>引入相关性约束后:<br><img src="/2017/06/28/CDL/2.png" alt="[after]" title="[after]"><br>$|| M ||_*$就表示迹范数(trace norm).是这样定义的:<br><img src="/2017/06/28/CDL/3.png" alt="[trace norm]" title="[trace norm]"><br>tr():表示矩阵的迹<br>inf():表示最大下界<br>$\Gamma$是一个半定矩阵.并由M得到.<br>将M引入公式,得到<br><img src="/2017/06/28/CDL/4.png" alt="[推导过程]" title="[推导过程]"><br>则反向传播中$W_N$和$W_V$的梯度:<br><img src="/2017/06/28/CDL/5.png" alt="[推导过程2]" title="[推导过程2]"><br>事实上这一步我也不懂.</p>
<h3 id="跨模态排名采样方法"><a href="#跨模态排名采样方法" class="headerlink" title="跨模态排名采样方法"></a>跨模态排名采样方法</h3><p>和triplet的思想类似,loss定义如下:<br><img src="/2017/06/28/CDL/6.png" alt="[Rank loss]" title="[Rank loss]"><br>在三元组中, a和n选自相同模态(如VIS)不同的类别, a和p选自相同的类别不同的模态.其约束如图:<br><img src="/2017/06/28/CDL/7.png" alt="[constraints]" title="[constraints]"></p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>使用light CNN作为基础网络.因为NIR-VIS的训练集很小, 先把网络在有大量VIS图片的数据集中训练, 然后用NIR-VIS微调.<br>在基础网络上修改,将上述的相关性约束和排名采样方法结合起来作为监督信号,如图:<br><img src="/2017/06/28/CDL/8.png" alt="[supervised signal]" title="[supervised signal]"><br>CDL的算法流程图:<br><img src="/2017/06/28/CDL/9.png" alt="[Algorithm 1]" title="[Algorithm 1]"></p>
<h2 id="疑问和思考"><a href="#疑问和思考" class="headerlink" title="疑问和思考"></a>疑问和思考</h2><p>线性代数部分的知识遗忘的比较厉害…</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/27/MTCNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/27/MTCNN/" itemprop="url">Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-27T19:28:41+08:00">
                2017-06-27
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-29T15:54:40+08:00">
                2017-06-29
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>参考:</p>
<ul>
<li><a href="http://blog.csdn.net/qq_14845119/article/details/52680940" target="_blank" rel="external">MTCNN（Multi-task convolutional neural networks）人脸对齐</a></li>
</ul>
<p>项目地址: <a href="https://github.com/kpzhang93/MTCNN_face_detection_alignment" target="_blank" rel="external">原版matlab</a>, <a href="https://github.com/DuinoDu/mtcnn" target="_blank" rel="external">python</a>, <a href="https://github.com/foreverYoungGitHub/MTCNN" target="_blank" rel="external">C++</a></p>
<h2 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h2><h3 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h3><p>整个方法如图所示:<br><img src="/2017/06/27/MTCNN/fig1.png" alt="[cascaded framework]" title="[cascaded framework]"><br>首先将一张图像调整至不同的大小来构建图像金字塔,作为下面操作的输入.</p>
<ol>
<li>通过一个名为P-Net的全由卷积层构建的网络获得候选的面部窗口和边界框回归向量.然后根据边界框回归向量对候选窗口进行校准, 并使用NMS合并高度重叠的候选窗口.</li>
<li>将候选窗口输入到另一个名为R-Net的CNN.它能拒绝掉大量的非人脸窗口.也需要用边界框回归向量校准和NMS.</li>
<li>与第二步类似,输入到一个名为O-Net的CNN中.但这一步用更多的监督来分辨人脸区域.最终输出5个面部基准点.</li>
</ol>
<h3 id="CNN结构"><a href="#CNN结构" class="headerlink" title="CNN结构"></a>CNN结构</h3><img src="/2017/06/27/MTCNN/fig2.png" alt="[The architectures]" title="[The architectures]">
<p>这一部分可以参考原版代码.<br>在卷积层后使用PReLU激活.</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>训练MTCNN包含3个部分, 人脸/非人脸分类器, 边界框回归和面部基准点定位。</p>
<ol>
<li>人脸分类:这是一个2分类问题.对于每一个样本$x_i$使用交叉熵计算loss.<img src="/2017/06/27/MTCNN/1.png" alt="[cross-entropy loss]" title="[cross-entropy loss]"></li>
<li>边界框回归:这是一个回归问题,使用欧式距离计算loss.(y有四个维度:左上角点的x,y,高度,宽度.下方公式前者是预测值,后者是实际值)</li>
<li>面部基准点定位:和边界框回归类似, 可看作回归问题, 也使用欧式距离计算loss.公式如上.(y表示基准点的坐标,共有5个点,故y有10维)</li>
<li>多资源训练:<img src="/2017/06/27/MTCNN/multi.png" alt="[目标函数]" title="[目标函数]"><br>N:训练样本数; $\alpha_j$:任务的重要程度. 在P-Net和R-Net使用(1, 0.5, 0.5)分配, 在O-Net使用(1, 0.5, 1)分配.$\beta$代表样本的标签.</li>
<li>线上的困难样本挖掘:在每个mini-batch中选出loss位于前70%的样本作为困难样本, 并且在BP阶段只利用这部分计算梯度.</li>
</ol>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>IoU表示与任何真实人脸的<strong>交并集</strong></p>
<ul>
<li>IoU&lt;0.3:非人脸(Negatives)</li>
<li>0.3&lt;IoU&lt;0.4:脸部基准点(landmarks)</li>
<li>0.4&lt;IoU&lt;0.65:部分人脸</li>
<li>IoU&gt;0.65:人脸</li>
</ul>
<p>训练集数据按以上划分方式,由3:1:1:2(非人脸:人脸:部分人脸:基准点)数据组成.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/27/center-loss/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/27/center-loss/" itemprop="url">A Discriminative Feature Learning Approach for Deep Face Recognition 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-27T12:34:20+08:00">
                2017-06-27
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-29T15:55:12+08:00">
                2017-06-29
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>发表于ECCV2016<br>项目地址: <a href="https://github.com/ydwen/caffe-face" target="_blank" rel="external">caffe</a>, <a href="https://github.com/pangyupo/mxnet_center_loss" target="_blank" rel="external">mxnet</a><br>参考:</p>
<ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;mid=2650325602&amp;idx=1&amp;sn=9bc6071bf62a4ccdde1df4b4c5ae39f4&amp;chksm=f235a568c5422c7ed7993b9d3b46bcd979d360605511284e4363a4a92f845019795569f8f3e9&amp;mpshare=1&amp;scene=1&amp;srcid=1028OCsg4y3EUMMTPjPzfrgo#rd" target="_blank" rel="external">【Technical Review】ECCV16 Center Loss及其在人脸识别中的应用</a></li>
<li><a href="http://www.jianshu.com/p/773fbd0b2472" target="_blank" rel="external">Center Loss - A Discriminative Feature Learning Approach for Deep Face Recognition 论文理解</a></li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>传统模型抽取出的深度特征比较分散, 是因为softmax loss仅仅区分数据.论文提出了一种新的损失函数center loss. 它可以让每个类学习一个特征中心, 减小类内的距离. 结合softmax loss就可以达到增大类间差异, 减小类内差异的效果.</p>
<h2 id="The-Proposed-Approach"><a href="#The-Proposed-Approach" class="headerlink" title="The Proposed Approach"></a>The Proposed Approach</h2><p>先用如下网络LeNet++训练MNIST数据集<br><img src="/2017/06/27/center-loss/LeNet.png" alt="[LeNet]" title="[LeNet]"><br>固定输出特征为2维,这样我们就可以在平面上看到结果.如图:<br><img src="/2017/06/27/center-loss/result1.png" alt="[softmax result]" title="[softmax result]"><br>结论: 虽然类间的差距已经明显, 但类内的差距依然较大.</p>
<h2 id="The-center-loss"><a href="#The-center-loss" class="headerlink" title="The center loss"></a>The center loss</h2><img src="/2017/06/27/center-loss/center_loss.png" alt="[center loss]" title="[center loss]">
<p>$c_{y_i}$代表$y_i$所在类的中心.<br>一次性将训练集的特征全部提取求出中心不现实, 论文中提出两个解决办法.</p>
<ol>
<li>在mini-batch中更新.</li>
<li>为了避免类别标错的图片使中心抖动, 使用$\alpha$来控制中心的学习率.见下下图Algorithm1-output-6</li>
</ol>
<p>center loss的梯度如下计算:<br><img src="/2017/06/27/center-loss/gradient.png" alt="[center loss gradient]" title="[center loss gradient]"><br>训练模型时将softmax loss与center loss结合, 设置$\lambda$来平衡两个loss函数.<br><img src="/2017/06/27/center-loss/step.png" alt="[step]" title="[step]"><br>不同的$\lambda$会带来不同的效果:<br><img src="/2017/06/27/center-loss/lambda.png" alt="[Different lambda]" title="[Different lambda]"><br>不同的λ对于特征的分布有很大的影响，合适的λ会提高网络的精确度。<br>center loss与contrastive loss,triplet loss相比, 不需要复杂的重建训练集,也不会造成数据戏剧性的大增.</p>
<p>实验部分见论文.注意激活函数使用了PReLU<br><img src="/2017/06/27/center-loss/prelu.png" alt="[ReLU & PReLU]" title="[ReLU & PReLU]"></p>
<h2 id="疑问和思考"><a href="#疑问和思考" class="headerlink" title="疑问和思考"></a>疑问和思考</h2><ol>
<li>为什么总loss不用(1-$\lambda$)a+$\lambda$b这样的形式?</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/26/GoogleNet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/26/GoogleNet/" itemprop="url">Going Deeper with Convolutions 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-26T18:50:47+08:00">
                2017-06-26
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-26T21:57:59+08:00">
                2017-06-26
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文由google发表于CVPR2015</p>
<h2 id="Introduction-amp-Related-Work"><a href="#Introduction-amp-Related-Work" class="headerlink" title="Introduction &amp; Related Work"></a>Introduction &amp; Related Work</h2><p>本文提出一个网络结构名为Inception. 它的特点是能提升对计算资源的使用效率.使得 在计算负担不变的情况下提升了网络的宽度和深度.它的前身GoogleNet(22层)在ILSVRC14中创下了验证和检测的记录.<br>GoogleNet借鉴了许多NIN的思想.其1x1的卷积核主要用于降维来解决计算瓶颈问题, 同时也能提高网络的深度和宽度.<br>检测(detection)方法来源于R-CNN.分两步:</p>
<ol>
<li>利用颜色, 文本等低层次的线索生成未知对象的位置提案.</li>
<li>在这些位置使用CNN分类器对物体进行检测.</li>
</ol>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>目前提升CNN性能的方法就是使网络变大变深. 但这也会增加计算的消耗, 并且容易导致过拟合. 增大的网络还会导致大量的计算资源被浪费.<br>解决这些问题的方法之一就是将全连接层改为稀疏连接层. 哪个结构用这个方法用的最好呢?对啦,就是我们的Inception结构.</p>
<h2 id="Architechture"><a href="#Architechture" class="headerlink" title="Architechture"></a>Architechture</h2><p>如图:<br><img src="/2017/06/26/GoogleNet/Inception.png" alt="[Inception module]" title="[Inception module]"><br>图片被多个大小的卷积核卷积, 提取出来的特征到下一层汇总.</p>
<h2 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h2><p>如图:<br><img src="/2017/06/26/GoogleNet/GoogleNet.png" alt="[GoogleNet]" title="[GoogleNet]"><br>可以参考阅读:<a href="https://github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/train_val.prototxt" target="_blank" rel="external">Caffe中GoogleNet的写法</a><br>#3x3 reduce代表3x3卷积前1x1滤波器的个数.<br>所有激活函数使用RELU.<br>第一个卷积层输出的计算为$\frac{224+2*3-7}{2}+1=112$(注意是向下取整)<br>第一个pool层输出的计算为$\frac{112-3}{2}+1$发现并不能整除.故一定自动补了padding.结果为56<br>inception(3a) 256 = 64(#1<em>1)+128(#3</em>3)+32(#5*5)+32(pool), 就是把各种方法得到的相同大小的结果拼接到一块输出.<br>使用avg pool层代替全连接层在top-1的准确率上获得了0.6%的提升.</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>采用<a href="http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf" target="_blank" rel="external">Large scale distributed deep networks</a>提到的分布置信网络(DistBelief). SGD+momentum的最优化方法, momentum=0.9, lr每8个epoch下降4%.详见论文.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/24/FaceNet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/24/FaceNet/" itemprop="url">FaceNet:A Unified Embedding for Face Recognition and Clustering 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-24T11:35:03+08:00">
                2017-06-24
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-24T22:55:04+08:00">
                2017-06-24
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文由GOOGLE于2015年发表在CVPR<br>参考:</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/24837264" target="_blank" rel="external">谷歌人脸识别系统FaceNet解析</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/46687471" target="_blank" rel="external">FaceNet–Google的人脸识别</a></li>
<li><a href="http://www.cnblogs.com/xiaohuahua108/p/6505756.html" target="_blank" rel="external">FaceNet—深度学习与人脸识别的二次结合</a></li>
</ul>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>本文提出一个系统名为FaceNet. 它可以直接将人脸图像映射至欧式空间, 其距离能直接反应出人脸间的相似度. 一旦生成该空间, 识别, 验证, 聚类等任务都可以用它来轻松完成. FaceNet在LFW上达到了99.63%的准确率, 在Youtube Faces DB达到95.12%.<br>和之前的方法(先输出高维度特征向量, 然后用PCA等降维, 再用分类器分类)不同, FaceNet直接使用基于triplets的LMNN（最大边界近邻分类）的loss函数训练神经网络, 网络直接输出为128维度的向量空间.<br>其人脸比对的结果如图所示:<br><img src="/2017/06/24/FaceNet/1.png" alt="[Illumination and Pose invariance]" title="[Illumination and Pose invariance]"><br>可以看到1.1就是阈值.</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>本文探索了2个网络.第一类为Zeiler&amp;Fergus研究中使用的神经网络, 受NIN影响, 我们在网络后面加了多个1*1*d卷积层, 第二类为Inception网络.<br>关键在于网络的末端使用了triplet loss作为目标函数. </p>
<h3 id="Triplet-Loss"><a href="#Triplet-Loss" class="headerlink" title="Triplet Loss"></a>Triplet Loss</h3><p>triplet loss: 在3个样本中,最小化类内差距,最大化类间差距.如图:<br><img src="/2017/06/24/FaceNet/triplet.png" alt="[Triplet Loss]" title="[Triplet Loss]"><br>公式如下:<br><img src="/2017/06/24/FaceNet/tripletloss.png" alt="[triplet loss公式]" title="[triplet loss公式]"></p>
<h3 id="Triplet-3个样本的选择"><a href="#Triplet-3个样本的选择" class="headerlink" title="Triplet 3个样本的选择"></a>Triplet 3个样本的选择</h3><p>我们想要从类内选择出一些P样本(hard-positive), 使他们与A样本的平均距离最大(argmax). 同时从类外选择出一些N样本(hard-negative), 使他们与A样本的平均距离最小(argmin). 但计算整个训练集之间的平均最大最小距离是不现实的.这里有两个办法解决它:</p>
<ol>
<li>每隔几步产生triplets, 计算它们在子数据集中的argmax和argmin. </li>
<li>在线产生triplets, 从mini-batch中得到hard positive/negative样本.(本文使用)</li>
</ol>
<p>文章选用方法2, 为了防止选择不当, 使用如下公式来约束样本选择.<br><img src="/2017/06/24/FaceNet/select.png" alt="[help to select]" title="[help to select]"></p>
<h3 id="深度卷积网络"><a href="#深度卷积网络" class="headerlink" title="深度卷积网络"></a>深度卷积网络</h3><p>第一个是Zeiler&amp;Fergus的22层网络.<br><img src="/2017/06/24/FaceNet/NN1.png" alt="[NN1]" title="[NN1]"><br>第二个网络<br><img src="/2017/06/24/FaceNet/NN2.png" alt="[NN2]" title="[NN2]"></p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ol>
<li>NN2(input 224*224)的效果最好.</li>
<li>即使图像只有80*80, 验证正确率下降的也不大.</li>
<li>NN1输出的特征在128维时效果最好.</li>
<li>训练的数据量增大能提高准确率.</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/23/DeepID2-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/23/DeepID2-1/" itemprop="url">Deeply learned face representations are sparse, selective, and robust 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-23T20:50:44+08:00">
                2017-06-23
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-25T16:23:09+08:00">
                2017-06-25
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文由香港中文大学于2015年发表在CVPR会议</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文设计了一个深度卷积网络, 获取到 的特征名为DeepID2+.相比与DeepID2,2+ 的网络通过增加隐层特征的维度和对靠前的卷积层监督使DeepID2+在LFW上表现很好.<br>对于人脸识别有3个点很关键:</p>
<ol>
<li>sparse: 稀疏, 即特征向量中包含很多零, 可压缩性强.</li>
<li>selective: 精选, 指具有判别能力的一些分量, 在不同人脸上响应程度不同.</li>
<li>robust: 健壮, 指图像被遮挡后特征中某些向量依然保持不变的一致性.</li>
</ol>
<h2 id="DeepID2-网络结构"><a href="#DeepID2-网络结构" class="headerlink" title="DeepID2+ 网络结构"></a>DeepID2+ 网络结构</h2><p>如图:<br><img src="/2017/06/23/DeepID2-1/Deepid2plus.png" alt="[DeepID2+ net]" title="[DeepID2+ net]"><br>DeepID2+网络也使用了识别和验证两种信号进行监督.此部分参考我上一篇笔记.<br>与DeepID2网络的不同点:</p>
<ol>
<li>每个卷积层后(实际上是1,2,3maxpool层和conv4层后)都获得一个128维的特征, 共有4个卷积层故特征从160维增大到512维.</li>
<li>训练集增大.从8000类160000图增大至12000类290000图.</li>
<li>用全连接层连接每个卷积层, 并使用DeepID2的那种监督方式.这样监督信号就离前期的卷积层更近了,也更有效.</li>
</ol>
<p>实验发现DeepID2选取了25个patch，DeepID2+选取了同样的25个patch，然后抽取的特征分别训练联合贝叶斯模型，得到的结果是DeepID2+平均比DeepID2提高2%。<br>特别的,根据稀疏性对DeepID2+进行二值化处理后, 再使用联合贝叶斯或汉明距离实验,发现识别率下降有限.二值化后的特征节省空间并且可以使人脸检索变得速度更快，更接近实用场景。</p>
<h2 id="关于DeepID3"><a href="#关于DeepID3" class="headerlink" title="关于DeepID3"></a>关于DeepID3</h2><p>DeepID3实现了两个更深的网络,一个参考VGG, 一个参考googlenet.<br>如图所示:<br><img src="/2017/06/23/DeepID2-1/DeepID3.png" alt="[Two DeepID3 Network]" title="[Two DeepID3 Network]"><br>但结果较DeepID2+差距不大.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/22/DeepID2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/22/DeepID2/" itemprop="url">Deep Learning Face Representation by Joint Identification-Verification 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-22T15:22:18+08:00">
                2017-06-22
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-22T22:55:05+08:00">
                2017-06-22
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文由香港中文大学于2014年发表<br>参考:</p>
<ul>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/41497545" target="_blank" rel="external">DeepID2——强大的人脸分类算法</a></li>
<li><a href="http://blog.csdn.net/u010318961/article/details/51967845" target="_blank" rel="external">经典计算机视觉论文笔记汇总</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/42091205" target="_blank" rel="external">DeepID人脸识别算法之三代</a></li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>人脸识别的中心主题应该是减少类内变化增大类间差异.<br>所谓识别(identification)是将一张图片从大量的类别中识别出来. 而所谓验证(verification)是比较两批图像是否为同一类.我们使用识别和验证两种信号(signal)得到的特征称为DeepID2. 使用DeepID2, 在LFW数据集上得到了99.15%的正确率</p>
<h2 id="特征抽取"><a href="#特征抽取" class="headerlink" title="特征抽取"></a>特征抽取</h2><p>DeepID2使用的结构:<br><img src="/2017/06/22/DeepID2/DeepID2.png" alt="[The ConvNet for DeepID2]" title="[The ConvNet for DeepID2]"><br>其网络结构与DeepID很相似,只不过输入图像的大小改为55*47.<br>DeepID2特征从两个监督信号学习得到.<br>首先是人脸识别信号, 识别通过在DeepID2层后接一个softmax层实现.loss表示为Ident loss<br>然后是人脸验证信号, 它能有效的减小类内变化, 通常有L1, L2, Cosine相似度3种形式, 文中使用L2.表示为Verif loss, 公式如下:<br><img src="/2017/06/22/DeepID2/L2.png" alt="[Verif loss]" title="[Verif loss]"><br>当图同类时($y_{ij}=1$)减小类内差距.<br>当图异类时($y_{ij}=-1$)增大类间差距至m, m是需要手动调节的.<br>余弦距离公式也给出, 但文章没有使用,我就不列出.<br>DeepID2特征学习算法:<br><img src="/2017/06/22/DeepID2/train.png" alt="[loss]" title="[loss]"><br>可以看到最终的目标函数(loss)是由Ident loss和Verif loss加权得到的.</p>
<h2 id="人脸验证"><a href="#人脸验证" class="headerlink" title="人脸验证"></a>人脸验证</h2><p>使用SDM获得人脸的21个基准点, 然后使用这些基准点将人脸图像对齐.<br>然后在不同的位置, 大小, 色彩通道和水平翻转切割每张人脸图像,每张图像得到400个不同的patch. 将其放入200个前文提到的深度卷积网络, 抽取出400个DeepID2特征向量.选择水平翻转的图像与原始图像作为一对, 放入网络得到2个DeepID2特征向量.<br>为了减少DeepID2特征的长度, 使用前向-反向贪心算法选择出25个特征向量. 25*160=4000维依然太大, 使用PCA将人脸特征向量压缩至180维, 然后使用联合贝叶斯算法进行人脸识别. 例子:<br><img src="/2017/06/22/DeepID2/25face.png" alt="[example]" title="[example]"></p>
<h2 id="疑问和思考"><a href="#疑问和思考" class="headerlink" title="疑问和思考"></a>疑问和思考</h2><ol>
<li>联合贝叶斯算法是什么样的?</li>
<li>SDM算法是什么?</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
      
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://asdf0982.github.io/2017/06/21/DeepID/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liam's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/21/DeepID/" itemprop="url">Deep Learning Face Representation from Predicting 10,000 Classes 阅读笔记</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-21T14:25:17+08:00">
                2017-06-21
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2017-06-22T15:07:26+08:00">
                2017-06-22
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文由香港中文大学于2014年发表在CVPR会议<br>参考:</p>
<ul>
<li><a href="http://www.cnblogs.com/zzq1989/p/4373680.html" target="_blank" rel="external">Deep Learning Face Representation from Predicting 10,000 Classes论文笔记</a></li>
<li><a href="http://blog.csdn.net/chenriwei2/article/details/31415069" target="_blank" rel="external">【深度学习论文笔记】Deep Learning Face Representation from Predicting 10,000 Classes</a></li>
<li><a href="http://blog.csdn.net/prm10/article/details/50598975" target="_blank" rel="external">Deep Learning Face Representation from Predicting 10,000 Classes</a></li>
<li><a href="http://blog.csdn.net/u010318961/article/details/51967845" target="_blank" rel="external">经典计算机视觉论文笔记——DeepFace\DeepID\DeepID2\DeepID3\FaceNet\VGGFace汇总</a></li>
</ul>
<h2 id="Introduction-and-Related-Work"><a href="#Introduction-and-Related-Work" class="headerlink" title="Introduction and Related Work"></a>Introduction and Related Work</h2><p>本文提供了一种用多个深度模型获得高水平人脸特征(DeepID)来对人脸分类的方法.所谓DeepID,假如网络有10000个分类的输出, 那么在最后一层的输入(倒数第二层的输出)就是DeepID的组成部分,文中有160维.如图<br><img src="/2017/06/21/DeepID/DeepID.png" alt="[DeepID]" title="[DeepID]"><br>DeepID有很好的泛化能力, 再对它用Joint Bayesian等方法就能进行人脸验证.</p>
<h2 id="Deep-ConvNets"><a href="#Deep-ConvNets" class="headerlink" title="Deep ConvNets"></a>Deep ConvNets</h2><p>结构如下:<br><img src="/2017/06/21/DeepID/ConvNet.png" alt="[ConvNet]" title="[ConvNet]"><br>输入图像为39*31*k, k表示通道数(RGB图像k为3, 灰度图像k为1).<br>激活函数使用RELU.<br>DeepID层为全连接层,其输入为Maxp3和Conv4两者.输出特征160维. 因Conv4包含了较多的全局信息, 需要Maxp3进行细节补充.<img src="/2017/06/21/DeepID/hiddenlayer.png" alt="[DeepID层(FC)公式]" title="[DeepID层(FC)公式]"><br>$x^1,w^1,x^2,w^2$代表Maxp3和Conv4的输出和对应的权重.<br>该模型使用SGD的最优化方法.</p>
<h2 id="Feature-extraction"><a href="#Feature-extraction" class="headerlink" title="Feature extraction"></a>Feature extraction</h2><p>找到人脸上的5个标记点.(两个眼睛中心点, 鼻尖点, 两个嘴角点)<br>将人脸根据两个眼睛中心点和嘴角连线的中点对齐.<br>从60个不同的小块抽取DeepID特征, 60这一数字源于10个区域, 3个大小, RGB和灰度2种通道.如图:<br><img src="/2017/06/21/DeepID/facepatch.png" alt="[face path]" title="[face path]"><br>上方的十张图是由中等大小尺寸切的.上方左边的5张图切自弱对齐后的全局区域,上方右边的5张图则分别以5个人脸标记点为中心切.下方代表3种大小.(每种大小又分为长方形和正方形两个形状.)<br>每张图片输出160维,一个patch有两张图片(一张是原始的,一张是<strong>水平翻转</strong>的副本),共有60个patch.则最终DeepID将所有维度连接起来,即160*2*60=19200维.这将用于最终的人脸验证.(每个网络输入一个patch,一张长方形一张正方形)</p>
<h2 id="Face-verification"><a href="#Face-verification" class="headerlink" title="Face verification"></a>Face verification</h2><p>分别使用JointBayesian和神经网络进行人脸识别.后续结果表面JointBayesian效果较好.<br>神经网络部分示意图:<br><img src="/2017/06/21/DeepID/NN.png" alt="[用于人脸识别的NN]" title="[用于人脸识别的NN]"><br>输入有640*60 是因为人脸识别需要两个张人脸图像.每张图像切好得到一个patch会产生160*2维输出.共有两张图像, 故640 = 160*2*2<br>注意到第一个隐层是locally-connect layer ,表示一个神经元只与对应的group连接, 这样神经元就能学习到紧凑的局部特征.第二的隐层为全连接层, 这表示从局部特征中学习全局特征.<br>隐层都使用RELU, 最后一层(输出)使用sigmoid.并且对所有隐层节点使用dropout.</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>采用CelebFace训练模型, 在LFW上验证.<br>随机选择80%的人训练DeepID模型, 剩下20%的人训练联合贝叶斯或神经网络.<br>在人脸识别阶段, 将特征通过PCA降维至150维, 再输入联合贝叶斯中.在测试时, 判断两张脸是否是同一个人是通过看联合贝叶斯的极大似然比来决定的, 该阈值通过训练集确定.<br>在LFW上的表现如下,其他结果见论文.<br><img src="/2017/06/21/DeepID/result.png" alt="[result in LFW]" title="[result in LFW]"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


      
    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar2.jpg"
               alt="Liam Wang" />
          <p class="site-author-name" itemprop="name">Liam Wang</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/asdf0982" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/ghat0982" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liam Wang</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (search_path.endsWith("json")) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
