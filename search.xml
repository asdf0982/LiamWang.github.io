<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CS231n学习笔记(RNN)]]></title>
    <url>%2F2017%2F06%2F14%2FCS231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-RNN%2F</url>
    <content type="text"><![CDATA[数据集准备:打开datesets内的shell文件,找到url拖至迅雷里下载至datasets并解压.运行至第三个代码块时可能运行至os.remove(fname)报错.是因为文件缓存被python打开无法删除导致的,注释掉这句即可.np.linspace在指定的间隔内返回均匀间隔的数字. Vanilla RNN: step forward打开cs231n/rnn_layers.py找到rnn_step_forward(x, prev_h, Wx, Wh, b)123a = prev_h.dot(Wh) + x.dot(Wx) + bnext_h = np.tanh(a)cache = (x, prev_h, Wh, Wx, b, next_h) 即next_h = tanh(x*Wx+pre_h*Wh+b) Vanilla RNN: step backward找到rnn_step_backward(dnext_h, cache)1234567x, prev_h, Wh, Wx, b, next_h = cacheda = dnext_h * (1 - next_h ** 2) #(N,H)dx = np.dot(da, Wx.T) #(N,D)dprev_h = np.dot(da, Wh.T) #(N,H)dWx = np.dot(x.T, da) #(D,H)dWh = np.dot(prev_h.T, da) #(H,H)db = np.sum(da, axis = 0) #(H,) 若激活函数为sigmoid,那么$f’(z) = f(z)(1-f)$若激活函数为tanh,那么$f’(z) = 1-(f(z))^2$ Vanilla RNN: forward12345678910N, T, D = x.shape(H,) = b.shapeh = np.zeros((N, T,H))prev_h = h0for t in range(T): xt = x[:, t, :] next_h,_ = rnn_step_forward(xt, prev_h, Wx, Wh, b) prev_h = next_h h[:, t, :] = prev_hcache = (x, h0, Wh, Wx, b, h) Vanilla RNN: backward1234567891011121314151617181920212223x, h0, Wh, Wx, b, h = cacheN, T, H = dh.shapeD = x.shape[2]next_h = h[:, T-1, :]dprev_h = np.zeros((N, H))dx = np.zeros((N, T, D))dh0 = np.zeros((N, H))dWx = np.zeros((D, H))dWh = np.zeros((H, H))db = np.zeros((H,))for t in range(T): t = T-1-t xt = x[:, t, :] #(N,D) if t==0: prev_h = h0 else: prev_h = h[:,t-1,:] step_cache = (xt, prev_h, Wh, Wx, b, next_h) next_h = prev_h dnext_h = dh[:, t, :] + dprev_h dx[:, t, :], dprev_h, dWxt, dWht, dbt = rnn_step_backward(dnext_h, step_cache) dWx, dWh, db = dWx+dWxt, dWh+dWht, db+dbtdh0 = dprev_h Word embedding: forward1234567N, T = x.shapeV, D = W.shapeout = np.zeros((N, T, D))for i in range(N): for j in range(T): out[i, j] = W[x[i,j]]cache = (x, W.shape)]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHPstorm10+wamp3.0环境搭建]]></title>
    <url>%2F2017%2F06%2F13%2FPHPstorm10wamp3%2F</url>
    <content type="text"><![CDATA[phpstorm10的破解过程和wamp的安装过程不展开讲了。下面说说如何配置phpstorm。第1步：wamp自带xDebug，找到php.ini，在末尾加入12345678910111213141516; XDEBUG Extensionzend_extension_ts = &quot;D:/wamp64/bin/php/php5.6.25/zend_ext/php_xdebug-2.4.1-5.6-vc11-x86_64.dll&quot;;[xdebug]xdebug.remote_enable = offxdebug.profiler_enable = offxdebug.profiler_enable_trigger = offxdebug.profiler_output_name = cachegrind.out.%t.%pxdebug.profiler_output_dir = &quot;d:/wamp64/tmp&quot;xdebug.show_local_vars=0xdebug.idekey=PhpStormxdebug.remote_enable = Onxdebug.remote_host=localhostxdebug.remote_port=9000xdebug.remote_handler=dbgp 注意：其中.dll和tmp的路径根据实际情况修改。 第2步： File-&gt;Settings-&gt;Languages&amp;Frame Works-&gt;Php-&gt;Interpreter 选择web服务器套件中php.exe的路径第3步： File-&gt;Settings-&gt;Languages&amp;Frame Works-&gt;Php-&gt;Servers 配置服务器相关设置:第4步： File-&gt;Settings-&gt;Languages&amp;Frame Works-&gt;Php-&gt;Debug-&gt;DBGp Proxy 配置相关设置：第5步： File-&gt;Settings-&gt;Languages&amp;Frame Works-&gt;Php-Debug 找到右边窗口对应的debug设置，把端口改成9000第6步：在主界面右上角运行调试配置中创建phpwebapplication（我的php文件在www文件下的test下 所以设置为test）第7步：安装chrome 扩展程序 —— xdebug helper 。点击phpstorm右上角的监听按钮。即可进行调试]]></content>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231n学习笔记(TensorFlow)]]></title>
    <url>%2F2017%2F06%2F11%2FCS231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-TensorFlow%2F</url>
    <content type="text"><![CDATA[完成作业: [TensorFlow.ipynb]跳过数据导入部分,直接进入model部分.tensorflow的api有很多,建议边写边查.api文档 simple_model12345678910111213141516171819202122232425262728293031323334# clear old variablestf.reset_default_graph()# setup input (e.g. the data that changes every batch)# The first dim is None, and gets sets automatically based on batch size fed inX = tf.placeholder(tf.float32, [None, 32, 32, 3])y = tf.placeholder(tf.int64, [None])is_training = tf.placeholder(tf.bool)def simple_model(X,y): # define our weights (e.g. init_two_layer_convnet) # setup variables Wconv1 = tf.get_variable("Wconv1", shape=[7, 7, 3, 32]) bconv1 = tf.get_variable("bconv1", shape=[32]) W1 = tf.get_variable("W1", shape=[5408, 10]) b1 = tf.get_variable("b1", shape=[10]) # define our graph (e.g. two_layer_convnet) a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1 h1 = tf.nn.relu(a1) h1_flat = tf.reshape(h1,[-1,5408]) y_out = tf.matmul(h1_flat,W1) + b1 return y_outy_out = simple_model(X,y)# define our losstotal_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)mean_loss = tf.reduce_mean(total_loss)# define our optimizeroptimizer = tf.train.AdamOptimizer(5e-4) # select optimizer and set learning ratetrain_step = optimizer.minimize(mean_loss) Wconv1 = tf.get_variable(&quot;Wconv1&quot;, shape=[7, 7, 3, 32])表示卷积核的大小为7*7,每个卷积核包含3个通道,共有32个卷积核. bconv1 = tf.get_variable(&quot;bconv1&quot;, shape=[32])32个卷积核,每个都包含1个偏置项. W1 = tf.get_variable(&quot;W1&quot;, shape=[5408, 10])已知stride,图像与卷积核的宽度高度,根据公式’H_n = 1 + (H + 2 * pad - HH)/stride’计算卷积后输出矩阵的大小,1+(32-7)/2 = 13, 故每个卷积核会输出一个13*13的矩阵(不再以通道区分),共有32个卷积核,故输出的参数总数为13*13*32 = 5408. 而CASIA-10是最终分10类的,所以取10. a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding=&#39;VALID&#39;) + bconv1 What does tf.nn.conv2d do in tensorflow? tensorflow conv2d的padding解释以及参数解释strides[0]和strides[3]必须为1.因为tensor的shape是[batch, height, width, channels]我们的stride只在中间两个中进行, 所以一般strides = [1, X, X, 1] total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)tf.one_hot()使用,即创建一个全零矩阵,将对应位置置1. Training the model on one epoch1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071def run_model(session, predict, loss_val, Xd, yd, epochs=1, batch_size=64, print_every=100, training=None, plot_losses=False): # have tensorflow compute accuracy correct_prediction = tf.equal(tf.argmax(predict,1), y) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # shuffle indicies train_indicies = np.arange(Xd.shape[0]) np.random.shuffle(train_indicies) training_now = training is not None #True # setting up variables we want to compute (and optimizing) # if we have a training function, add that to things we compute variables = [mean_loss,correct_prediction,accuracy] if training_now: variables[-1] = training # counter iter_cnt = 0 for e in range(epochs): # keep track of losses and accuracy correct = 0 losses = [] # make sure we iterate over the dataset once for i in range(int(math.ceil(Xd.shape[0]/batch_size))):#也许最后还有一些训练集没有被纳入,也就不管它们了,宁缺毋滥 # generate indicies for the batch start_idx = (i*batch_size)%Xd.shape[0] #batch索引起始位置 idx = train_indicies[start_idx:start_idx+batch_size] #一个batch所有索引(已打乱) # create a feed dictionary for this batch feed_dict = &#123;X: Xd[idx,:], y: yd[idx], is_training: training_now &#125; # get batch size actual_batch_size = yd[idx].shape[0] # have tensorflow compute loss and correct predictions # and (if given) perform a training step loss, corr, _ = session.run(variables,feed_dict=feed_dict) # aggregate performance stats losses.append(loss*actual_batch_size) correct += np.sum(corr) # print every now and then if training_now and (iter_cnt % print_every) == 0: print("Iteration &#123;0&#125;: with minibatch training loss = &#123;1:.3g&#125; and accuracy of &#123;2:.2g&#125;"\ .format(iter_cnt,loss,np.sum(corr)/actual_batch_size)) #.ng表示n位有效数字 iter_cnt += 1 total_correct = correct/Xd.shape[0] total_loss = np.sum(losses)/Xd.shape[0] print("Epoch &#123;2&#125;, Overall loss = &#123;0:.3g&#125; and accuracy of &#123;1:.3g&#125;"\ .format(total_loss,total_correct,e+1)) if plot_losses: plt.plot(losses) plt.grid(True) plt.title('Epoch &#123;&#125; Loss'.format(e+1)) plt.xlabel('minibatch number') plt.ylabel('minibatch loss') plt.show() return total_loss,total_correctwith tf.Session() as sess: with tf.device("/cpu:0"): #"/cpu:0" or "/gpu:0" sess.run(tf.global_variables_initializer()) print('Training') run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,True) print('Validation') run_model(sess,y_out,mean_loss,X_val,y_val,1,64) correct_prediction = tf.equal(tf.argmax(predict,1), y)tf.argmax是一个非常有用的函数，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签，比如tf.argmax(predict,1)返回的是模型对于任一输入x预测到的标签值.tf.equal返回一个布尔数组,如[True, False, True, True] accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))可以使用tf.cast()函数将其转换为布尔值转换为[1, 0, 1, 1]，以方便准确率的计算.tf.reduce_mean可跨越维度的计算张量各元素的平均值. np.random.shuffle(train_indicies)以随机次序重组序列 Training a specific model1234567891011121314151617181920212223def complex_model(X,y,is_training): Wconv1 = tf.get_variable(&quot;Wconv1&quot;, shape=[7, 7, 3, 32]) bconv1 = tf.get_variable(&quot;bconv1&quot;, shape=[32]) W1 = tf.get_variable(&quot;W1&quot;, shape=[5408, 1024]) b1 = tf.get_variable(&quot;b1&quot;, shape=[1024]) W2 = tf.get_variable(&quot;W2&quot;, shape=[1024, 10]) b2 = tf.get_variable(&quot;b2&quot;, shape=[10]) # define our graph (e.g. two_layer_convnet) a1 = tf.nn.conv2d(X, Wconv1, strides=[1,1,1,1], padding=&apos;VALID&apos;) + bconv1 #print (a1.shape) h1 = tf.nn.relu(a1) h2 = tf.contrib.layers.batch_norm(h1, center=True, scale=True, is_training=True, scope=&apos;bn&apos;) pool1 = tf.layers.max_pooling2d(inputs=h2, pool_size=[2, 2], strides=2) pool1_flat = tf.reshape(pool1,[-1,5408]) y_1 = tf.matmul(pool1_flat,W1) + b1 y_1_new = tf.nn.relu(y_1) y_out = tf.matmul(y_1_new,W2) + b2 return y_out 经过conv层,a1.shape = [?,26,26,32],再经过maxpooling层,pool1_flat的参数个数为(26*26*32)/(2*2) = 5408 Train a great model on CIFAR-10!部分的模型在最开始的文件里.]]></content>
      <tags>
        <tag>Deep Learning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Install tensorflow on Win10]]></title>
    <url>%2F2017%2F06%2F10%2Finstall-tensorflow%2F</url>
    <content type="text"><![CDATA[install anaconda3I use Anaconda2 and my python version is 2.7, but tensorflow needs python3.5. So the first step is to build python2.7 and 3.5 coexistence environment. If you have already installed Anaconda2, you need download Anaconda3. (choose 4.2.0) Install it and change install path to “D:\Anaconda2\envs\Anaconda3”(D:\Anaconda2 is your Anaconda2’s path) Cancel the default check when installing the software. 12345# To activate this environment, use:# &gt; activate Anaconda3## To deactivate this environment, use:# &gt; deactivate Anaconda3 you can activate Anaconda3 and then python to check your python version. tensorflowlook at install_windows activate Anaconda3 update pip (Anaconda3) D:\&gt;python -m pip install --upgrade pip if your PC don’t hava a GPU 1(Anaconda3) D:\&gt;pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.1.0-cp35-cp35m-win_amd64.whl if you succeed, you can see 12Installing collected packages: numpy, six, werkzeug, setuptools, protobuf, wheel, tensorflowSuccessfully installed numpy-1.13.0 protobuf-3.3.0 setuptools-36.0.1 six-1.10.0 tensorflow-1.1.0 werkzeug-0.12.2 wheel-0.29.0 Invoke python from your shell as follows:$ pythonEnter the following short program inside the python interactive shell: 1234&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; hello = tf.constant(&apos;Hello, TensorFlow!&apos;)&gt;&gt;&gt; sess = tf.Session()&gt;&gt;&gt; print(sess.run(hello)) If the system outputs the following, then you are ready to begin writing TensorFlow programs:1Hello, TensorFlow!]]></content>
      <tags>
        <tag>Deep Learning</tag>
        <tag>tensorflow</tag>
        <tag>Tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231n学习笔记(卷积网络)]]></title>
    <url>%2F2017%2F06%2F08%2FCS231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[完成作业: [ConvolutionalNetworks.ipynb] [cnn.py] [layers.py] Convolution: Naive forward pass pad=x就是在图像边缘加x圈零,stride=2就是卷积核(fliter)在横向和纵向移动的时候都要空一格.12345678910111213stride, pad = conv_param['stride'], conv_param['pad']N, C, H, W = x.shapeF, C, HH, WW = w.shapex_padded = np.pad(x, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')H_n = 1 + (H + 2 * pad - HH) / strideW_n = 1 + (W + 2 * pad - WW) / strideout = np.zeros((N, F, H_n, W_n))for i in xrange(N): # ith image for f in xrange(F): # fth filter for j in xrange(H_n): for k in xrange(W_n): out[i, f, j, k] = np.sum(x_padded[i, :, j*stride:HH+j*stride, k*stride:WW+k*stride] * w[f]) + b[f] 图像的切割1234kitten, puppy = imread('kitten.jpg'), imread('puppy.jpg')# kitten is wide, and puppy is already squared = kitten.shape[1] - kitten.shape[0]kitten_cropped = kitten[:, d//2:-d//2, :] #kitten[Channel,Wide,height] 切割图像成为一个正方形.图像的3个通道分别是红,绿,蓝.也就是RGB 图像的放缩123img_size = 200 # Make this smaller if it runs too slowx = np.zeros((2, 3, img_size, img_size))x[0, :, :, :] = imresize(puppy, (img_size, img_size)).transpose((2, 0, 1)) imresize(puppy, (img_size, img_size))的形状是(200L, 200L, 3L)transpose((2,0,1))是以原来的shape按0,1,2这样排,然后去2,0,1重排得到结果.故x[0, :, :, :]的形状是(3L, 200L, 200L) Convolution: Naive backward pass123456789101112131415161718192021222324252627x, w, b, conv_param = cachepad = conv_param[&apos;pad&apos;]stride = conv_param[&apos;stride&apos;]F, C, HH, WW = w.shapeN, C, H, W = x.shapeH_new = 1 + (H + 2 * pad - HH) / strideW_new = 1 + (W + 2 * pad - WW) / stridedx = np.zeros_like(x)dw = np.zeros_like(w)db = np.zeros_like(b)s = stridex_padded = np.pad(x, ((0, 0), (0, 0), (pad, pad), (pad, pad)), &apos;constant&apos;)dx_padded = np.pad(dx, ((0, 0), (0, 0), (pad, pad), (pad, pad)), &apos;constant&apos;)for i in xrange(N): # ith image for f in xrange(F): # fth filter for j in xrange(H_new): for k in xrange(W_new): window = x_padded[i, :, j*s:HH+j*s, k*s:WW+k*s] db[f] += dout[i, f, j, k] dw[f] += window * dout[i, f, j, k] dx_padded[i, :, j*s:HH+j*s, k*s:WW+k*s] += w[f] * dout[i, f, j, k]# Unpaddx = dx_padded[:, :, pad:pad+H, pad:pad+W] Max pooling: Naive forward 123456789101112HH, WW = pool_param[&apos;pool_height&apos;], pool_param[&apos;pool_width&apos;]s = pool_param[&apos;stride&apos;]N, C, H, W = x.shapeH_new = 1 + (H - HH) / sW_new = 1 + (W - WW) / sout = np.zeros((N, C, H_new, W_new))for i in xrange(N): for j in xrange(C): for k in xrange(H_new): for l in xrange(W_new): window = x[i, j, k*s:HH+k*s, l*s:WW+l*s] out[i, j, k, l] = np.max(window) Max pooling: Naive backward1234567891011121314x, pool_param = cacheHH, WW = pool_param[&apos;pool_height&apos;], pool_param[&apos;pool_width&apos;]s = pool_param[&apos;stride&apos;]N, C, H, W = x.shapeH_new = 1 + (H - HH) / sW_new = 1 + (W - WW) / sdx = np.zeros_like(x)for i in xrange(N): for j in xrange(C): for k in xrange(H_new): for l in xrange(W_new): window = x[i, j, k*s:HH+k*s, l*s:WW+l*s] m = np.max(window) dx[i, j, k*s:HH+k*s, l*s:WW+l*s] = (window == m) * dout[i, j, k, l] 在编译python setup.py build_ext --inplace时遇到没有C语言编译环境的问题解决:windows下安装python的C扩展编译环境(解决“Unable to find vcvarsall.bat”) Spatial batch normalization: forward1234N, C, H, W = x.shapex_new = x.transpose(0, 2, 3, 1).reshape(N*H*W, C)out, cache = batchnorm_forward(x_new, gamma, beta, bn_param)out = out.reshape(N, H, W, C).transpose(0, 3, 1, 2) Spatial batch normalization: backward1234N, C, H, W = dout.shapedout_new = dout.transpose(0, 2, 3, 1).reshape(N*H*W, C)dx, dgamma, dbeta = batchnorm_backward(dout_new, cache)dx = dx.reshape(N, H, W, C).transpose(0, 3, 1, 2)]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231n学习笔记(批量归一化和dropout)]]></title>
    <url>%2F2017%2F06%2F06%2FCS231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%89%2F</url>
    <content type="text"><![CDATA[引言大意： 使深层网络更容易训练的一种方法是使用更复杂的优化程序，如SGD +momentum，RMSProp或Adam。 另一个策略是改变网络架构，使其更容易训练。这些方面的一个想法是最近提出的批量归一化(Batch normalization)这个想法比较简单。 当机器学习方法的输入数据由零均值和单位方差的不相关特征组成时，往往会更好地工作。 在训练神经网络时，我们可以在将数据馈送到网络之前对数据进行预处理，以明确地解耦其特征; 这将确保网络的第一层看到遵循良好分发的数据。 然而，即使我们对输入数据进行预处理，网络较深层的激活可能不会再去相关，并且不再具有零均值或单位方差，因为它们是从网络中较早的层输出的。 更糟糕的是，在训练过程中，网络每层的特征分布将随着每个层的权重更新而移动。[3]的作者假设深层神经网络中特征的偏移分布可能使训练深层网络更加困难。 为了克服这个问题，[3]提出将批量归一化层插入到网络中。 在训练时间内，批量归一化层使用数据的小批量来估计每个特征的平均值和标准偏差。 然后使用这些估计的平均值和标准偏差来中心和标准化小型化的特征。 在训练期间，这些平均值和标准偏差的平均值保持不变，在测试时，这些运行平均值用于对特征进行中心和归一化。这种归一化策略有可能降低网络的代表性能力，因为某些层有时可能具有非零均值或单位方差特征的优化。 为此，批量归一化层包括每个特征维度的可学习的移位和缩放参数。[3] Sergey Ioffe and Christian Szegedy, “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift”, ICML 2015. Batch normalization: Forward先上公式 再上关键代码块1234567sample_mean = np.mean(x, axis=0, keepdims=True) # [1,D] sample_var = np.var(x, axis=0, keepdims=True) # [1,D] x_normalized = (x - sample_mean) / np.sqrt(sample_var + eps) # [N,D] out = gamma * x_normalized + beta cache = (x_normalized, gamma, beta, sample_mean, sample_var, x, eps) running_mean = momentum * running_mean + (1 - momentum) * sample_mean running_var = momentum * running_var + (1 - momentum) * sample_var gamma和std对应，beta和mean对应。 Batch Normalization: backward 12345678910111213x_normalized, gamma, beta, sample_mean, sample_var, x, eps = cacheN, D = x.shapedx_normalized = dout * gamma # [N,D]x_mu = x - sample_mean # [N,D]sample_std_inv = 1.0 / np.sqrt(sample_var + eps) # [1,D]dsample_var = -0.5 * np.sum(dx_normalized * x_mu, axis=0, keepdims=True) * sample_std_inv**3dsample_mean = -1.0 * np.sum(dx_normalized * sample_std_inv, axis=0, keepdims=True) - \ 2.0 * dsample_var * np.mean(x_mu, axis=0, keepdims=True)dx1 = dx_normalized * sample_std_invdx2 = 2.0/N * dsample_var * x_mudx = dx1 + dx2 + 1.0/N * dsample_meandgamma = np.sum(dout * x_normalized, axis=0, keepdims=True)dbeta = np.sum(dout, axis=0, keepdims=True) dout就是loss关于yi的偏导数。 dropout_forward 12mask = (np.random.rand(*x.shape) &lt; p) / pout = x * mask p代表节点生效的概率。最后除以p是为了让整体的均值不变。 dropout_backward1dx = dout * mask]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231n学习笔记(全连接网络)]]></title>
    <url>%2F2017%2F06%2F01%2FCS231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[完成作业： [FullyConnectedNets.ipynb] [fc_net.py] [layers.py] [layer_utils.py] [optim.py] 这次作业非常重要，是assignment1的一次总结和大提升，我感觉应该反复咀嚼，琢磨透。进入了assignment2学习，打开FullyConnectedNets.ipynb，有一大段引言我试着翻译一下。 在之前的作业中，你在CIFAR-10数据集上实现了一个2层的全连接神经网络。这次简单的实现并不十分模块化，因为loss和梯度都在一块函数中计算。对于一个简单的2层网络来说，这样是可管理的。但随着我们向更大的模型推进时，这样做又变得不切实际。在理想情况下，我们希望使用更模块化的设计来独立实现不同类型的层，然后根据不同模型的结构把他们拼到一起。这次作业我们将使用更模块化的方法来实现一个全连接的神经网络。每一层我们都将实现一个前向和反向传播的功能。前向传播接收输入，权重和其他参数，并返回反向传播所需的输出和缓存对象。如下： 12345678910def layer_forward(x, w): """ Receive inputs x and weights w """ # Do some computations ... z = # ... some intermediate value # Do some more computations ... out = # the output cache = (x, w, z, out) # Values we need to compute gradients return out, cache 而反向传播将接收上行导数（？）和缓存对象，并返回根据梯度调整的输入和权重。如下：12345678910111213def layer_backward(dout, cache): """ Receive derivative of loss with respect to outputs and cache, and compute derivative with respect to inputs. """ # Unpack cache values x, w, z, out = cache # Use values in cache to compute derivatives dx = # Derivative of loss with respect to x dw = # Derivative of loss with respect to w return dx, dw 以这种模块化的方式实现了一些层后，我们就可以轻松地把它们组合起来去构建不同结构的分类器了。除了能实现任意深度的全连接网络，我们也能探索不同的最优化更新规则并引入Dropout方法作为规则化和批规范化的工具使优化深度网络更高效。 fc_net.init12345678910111213141516############################################################################# TODO: Initialize the weights and biases of the two-layer net. Weights ## should be initialized from a Gaussian with standard deviation equal to ## weight_scale, and biases should be initialized to zero. All weights and ## biases should be stored in the dictionary self.params, with first layer ## weights and biases using the keys 'W1' and 'b1' and second layer weights ## and biases using the keys 'W2' and 'b2'. ##############################################################################根据上面的提示，权重W需要初始化在一个标准差为weight_scale的高斯（正态）分布矩阵#故在W1生成input_dim行，hidden_dim列的高斯矩阵self.params['W1'] = weight_scale * np.random.randn(input_dim,hidden_dim) #D,H#权重b应该被初始化为零self.params['b1'] = np.zeros((1,hidden_dim)) #1,H#同理W2，b2self.params['W2'] = weight_scale * np.random.randn(hidden_dim,num_classes) #H,Cself.params['b2'] = np.zeros((1,num_classes)) #1,C fc_net.loss12345678910111213141516171819202122232425262728293031323334353637383940414243scores = None############################################################################# TODO: Implement the forward pass for the two-layer net, computing the ## class scores for X and storing them in the scores variable. #############################################################################W1, b1, W2, b2 = self.params['W1'], self.params['b1'], self.params['W2'],self.params['b2']# Forward into first layerhidden_layer, cache_hidden_layer = affine_relu_forward(X, W1, b1)# Forward into second layerscores, cache_scores = affine_forward(hidden_layer, W2, b2)############################################################################# END OF YOUR CODE ############################################################################## If y is None then we are in test mode so just return scoresif y is None: return scoresloss, grads = 0, &#123;&#125;############################################################################# TODO: Implement the backward pass for the two-layer net. Store the loss ## in the loss variable and gradients in the grads dictionary. Compute data ## loss using softmax, and make sure that grads[k] holds the gradients for ## self.params[k]. Don't forget to add L2 regularization! ## ## NOTE: To ensure that your implementation matches ours and you pass the ## automated tests, make sure that your L2 regularization includes a factor ## of 0.5 to simplify the expression for the gradient. #############################################################################data_loss, dscores = softmax_loss(scores, y)reg_loss = 0.5 * self.reg * (np.sum(W1**2) + np.sum(W2**2))loss = data_loss + reg_loss# Backprop into second layerdx1, dW2, db2 = affine_backward(dscores,cache_scores)dW2 += self.reg * W2# Backprop into first layerdx, dW1, db1 = affine_relu_backward(dx1, cache_hidden_layer)dW1 += self.reg * W1grads.update(&#123;'W1': dW1, 'b1': db1, 'W2': dW2, 'b2': db2&#125;) 正向的计算不多说了，反向传播说一下。先理理思路softmax层最终计算出了的是loss，我们希望loss下降，于是也给出了loss关于score的偏导数dscore。即$dscores = \frac{\partial loss}{\partial scores}$,于是想要求dx1,只要用链式法则$dx1 = \frac{\partial loss}{\partial scores}*\frac{\partial scores}{\partial x1}$可得到即hidden_layer的梯度。 最优化方法推荐文章： An overview of gradient descent optimization algorithms 中文版 卷积神经网络中的优化算法比较（这篇文章包含代码，便于理解） 深度学习最全优化方法总结比较 注意：在RMSprop方法的eps是在sqr内的，二号文章的代码将其放在外。]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Date型数据在SSM架构下的参数绑定与回显]]></title>
    <url>%2F2017%2F05%2F31%2FDate%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%9C%A8SSM%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A%E4%B8%8E%E5%9B%9E%E6%98%BE%2F</url>
    <content type="text"><![CDATA[Date型数据有很多种表现形式，传递起来相对来说比较复杂。最近做的项目涉及到这方面内容，做个笔记。 Date型数据的参数绑定。想要将jsp页面收到String型参数转为Date型参数再保存到实体类中，首先需要创建一个转换器。创建Controller包,姑且命名为liam.ssm.controller.converter。在其中创建一个类(Class),命名为CustomDateConverter.java123456789101112131415public class CustomDateConverter implements Converter&lt;String, Date&gt; &#123; @Override public Date convert(String source) &#123; try &#123; SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); //String型数据的格式为"yyyy-MM-dd HH:mm:ss"才能被正确转换 return simpleDateFormat.parse(source); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; //转换失败返回空 &#125;&#125; 然后由于spingmvc使用注解驱动。需要在配置文件(springmvc.xml)将刚刚设置的转换器配置进去。123456789101112&lt;mvc:annotation-driven conversion-service="conversionService"&gt;&lt;/mvc:annotation-driven&gt;&lt;!-- conversionService --&gt; &lt;bean id="conversionService" class="org.springframework.format.support.FormattingConversionServiceFactoryBean"&gt; &lt;!-- 转换器 --&gt; &lt;property name="converters"&gt; &lt;list&gt; &lt;bean class="liam.ssm.controller.converter.CustomDateConverter"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; 这样参数绑定就完成了，下面看看jsp中的相关代码1&lt;input name="liam.time" id="time" value="2017-5-31 18:02:12"/&gt; 到后台controller，假如我们创建过liam这个实体类，那么time这个参数应该能正确传递。（本质上以上的操作均属于自定义的参数绑定，可以应用到其他类型绑定上去。）1234@RequestMapping("/test") public String test(Liam liam)throws Exception&#123; //TODO 设置有个断点，进来看看liam内包含的time是否正确 &#125; Date型数据的回显如果简单使用&lt;input name=&quot;liam.time&quot; id=&quot;time&quot; value=&quot;${liam.time}&quot;/&gt;会发现显示的时间是Wed May 31 18:11:32 CST 2017这样的形式。为了将其原模原样的回显成yyyy-MM-dd HH:mm:ss格式我使用JSTL标签。12&lt;%@taglib uri="http://java.sun.com/jsp/jstl/fmt" prefix="fmt"%&gt;&lt;fmt:formatDate value="$&#123;liam.time&#125;" pattern="yyyy-MM-dd HH:mm:ss"/&gt; 如果想要在input输入框回显，不显示具体时间，则这样1&lt;input name=&quot;liam.time&quot; value=&apos;&lt;fmt:formatDate value=&quot;$&#123;liam.time &#125;&quot; pattern=&quot;yyyy-MM-dd&quot; /&gt;&apos; /&gt; 注意：yyyy-MM-dd HH:mm:ss中的字符大小写不要随意修改，也许包含不同的含义。 字母 日期或时间元素 表示 示例 G Era 标志符 Text AD y 年 Year 1996 ; 96 M 年中的月份 Month July ; Jul ; 07 w 年中的周数 Number 27 W 月份中的周数 Number 2 D 年中的天数 Number 189 d 月份中的天数 Number 10 F 月份中的星期 Number 2 E 星期中的天数 Text Tuesday ; Tue a Am/pm 标记 Text PM H 一天中的小时数（0-23） Number 0 k 一天中的小时数（1-24） Number 24 K am/pm 中的小时数（0-11） Number 0 h am/pm 中的小时数（1-12） Number 12 m 小时中的分钟数 Number 30 s 分钟中的秒数 Number 55 S 毫秒数 Number 978 z 时区 General time zone Pacific Standard Time ; PST ; GMT-08:00 Z 时区 RFC 822 time zone -0800]]></content>
      <tags>
        <tag>spring mvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231n学习笔记-两层网络]]></title>
    <url>%2F2017%2F05%2F29%2FCS231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%A4%E5%B1%82%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[完成作业 [two_layer_net.ipynb] [neural_net.py] 前向传播计算图像在各类下的分数在neural_net.py下编辑loss函数123L1 = ReLU(np.dot(X,W1)+b1)L2 = np.dot(L1,W2)+b2 # N,Cscores = L2 L1代表第一层，使用ReLU作为激活函数。而ReLU函数没有定义，所以需要在TwoLayerNet外建一个。12def ReLU(x): return np.maximum(0,x) # f(z) = max(0, z) .ipynb文件中预置了正确答案，可以进行比对。我的如下：12345678910111213141516Your scores:[[-0.81233741 -1.27654624 -0.70335995] [-0.17129677 -1.18803311 -0.47310444] [-0.51590475 -1.01354314 -0.8504215 ] [-0.15419291 -0.48629638 -0.52901952] [-0.00618733 -0.12435261 -0.15226949]]correct scores:[[-0.81233741 -1.27654624 -0.70335995] [-0.17129677 -1.18803311 -0.47310444] [-0.51590475 -1.01354314 -0.8504215 ] [-0.15419291 -0.48629638 -0.52901952] [-0.00618733 -0.12435261 -0.15226949]]Difference between your scores and correct scores:3.68027204961e-08 计算loss1234567scores_max = np.max(scores, axis=1, keepdims=True)exp_scores = np.exp(scores - scores_max)probs = exp_scores/np.sum(exp_scores, axis=1, keepdims=True)correct_logprobs = -np.log(probs[range(N),y])data_loss = np.sum(correct_logprobs)/Nreg_loss = 0.5 * reg * (np.sum(W1**2)+np.sum(W2**2))loss = data_loss + reg_loss 这里使用softmax的方法来计算。第一句keepdims参数设置为True时，scores_max.shape为(5,1),方便之后shape为(5,3)的scores通过广播能与score_max相减。keepdim使用说明 计算gradient1234567891011121314151617181920descores = probs # N,Cdescores[range(N),y] += -1descores /= N# W2,b2dW2 = np.dot(L1.T, descores) # H,Cdb2 = np.sum(descores,axis=0,keepdims=True) # 1,C# L1dL1 = np.dot(descores,W2.T) # N,H# ReLudL1[L1 &lt;= 0] = 0# W1,b1dW1 = np.dot(X.T,dL1) # D,Hdb1 = np.sum(dL1,axis=0,keepdims=True)# regularizationdW1 += reg * W1dW2 += reg * W2grads['W1'] = dW1grads['b1'] = db1grads['W2'] = dW2grads['b2'] = db2 softmax作业中gradient是严格按照公式计算的，如下123y_trueClass = np.zeros_like(prob)y_trueClass[range(num_train), y] = 1.0 # N by CdW += -np.dot(X.T, y_trueClass - prob) / num_train + reg * W 而这次作业里代码将公式中第一个负号去掉，trueclass与prob位置对调。 微调参数我调整了迭代次数，学习率和学习率下降等参数。训练后用图像展示训练过程，发现最好的模型就在默认的提供的参数附近哈哈哈。12345678910111213plt.subplot(2, 1, 1)plt.plot(mytrain['loss_history'])plt.title('Loss history')plt.xlabel('Iteration')plt.ylabel('Loss')plt.subplot(2, 1, 2)plt.plot(mytrain['train_acc_history'], label='train')plt.plot(mytrain['val_acc_history'], label='val')plt.title('Classification accuracy history')plt.xlabel('Epoch')plt.ylabel('Clasification accuracy')plt.show() 我很喜欢这样的图片展示，这是我其中一个模型的。]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231n学习笔记(softmax)]]></title>
    <url>%2F2017%2F05%2F28%2FCS231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-softmax%2F</url>
    <content type="text"><![CDATA[完成作业: [softmax.ipynb] [softmax.py] softmax的计算方式与SVM类似。参考此图其loss和gradient的计算推导过程如图]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UEditor的数据回显]]></title>
    <url>%2F2017%2F05%2F26%2FUEditor%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9B%9E%E6%98%BE%2F</url>
    <content type="text"><![CDATA[最近遇到了ueditor的不能显示数据的回显问题。解决思路： 在jsp页面添加div类型的隐藏栏，作为中转站保存数据。 使用js代码配置ueditor面板，从上获得数据并展示 12&lt;div id="temp" style="display: none;"&gt;$&#123;***.**&#125;&lt;/div&gt;&lt;srcipt id="container" name="content" type="text/plain"&gt;&lt;/srcipt&gt; 12345&lt;script type="text/javascript"&gt;var ue = UE.getEditor('container');ue.ready(function()&#123;ue.setContent($('#temp').html());&#125;); Tips： 最初我用的办法是&lt;input id=&quot;temp&quot; type=&quot;hidden&quot; value=&quot;${***.**}&quot;&gt;和ue.setContent($(&#39;#temp&#39;).val());图像和信息能正确上传但不能回显。原因是数据库中图像的内容为&lt;p&gt;&lt;img src=&quot;http://localhost:8080/…/ueditor/jsp/upload/image/20170602/**.png……&quot;&gt;这里src=之后的双引号会和value=后的双引号配对，导致图像的路径信息无法传入，所以改为上面的方法。 使用eclipse+tomcat调试项目，图像保存在workspace\.metadata\.plugins\org.eclipse.wst.server.core\tmp0\wtpwebapps\myown\ueditor\jsp\upload\image下的日期目录（其中workspace代表eclipse的默认工程路径，myown是我的项目名称）。在eclipse项目内点击ueditor-&gt;jsp-&gt;config.json中调整图像的保存路径。我修改为&quot;imageUrlPrefix&quot;: &quot;/myown&quot;,]]></content>
      <tags>
        <tag>Tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[连接电脑时蓝牙耳机音质明显下降]]></title>
    <url>%2F2017%2F05%2F25%2F%E8%BF%9E%E6%8E%A5%E7%94%B5%E8%84%91%E6%97%B6%E8%93%9D%E7%89%99%E8%80%B3%E6%9C%BA%E9%9F%B3%E8%B4%A8%E6%98%8E%E6%98%BE%E4%B8%8B%E9%99%8D%2F</url>
    <content type="text"><![CDATA[先比较连接手机时的音质，判断是否为耳机自身故障。 确定非耳机故障时，右击【蓝牙设备】图标-【显示蓝牙设备】 在相关设置下选择【设备和打印机】 右击【蓝牙耳机】图标-声音设置 观察到一个耳机却又两个模式，点开Stereo模式的【属性】-选择【高级】 观察到“2通道，CD音质”说明现在使用的耳机模式是听音乐的。 作为对比回去再打开Hands-Free模式的【属性】【高级】 观察到“1通道，电话音质”，这就是我之前使用的，音质明显下降的版本。 选择Stereo为默认模式。]]></content>
      <tags>
        <tag>Tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231n 学习笔记(SVM)]]></title>
    <url>%2F2017%2F05%2F24%2FCS231n-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-SVM%2F</url>
    <content type="text"><![CDATA[完成作业： [svm.ipynb] [linear_svm.py] [linear_classifier.py] hstack(),vstack()12345678910111213141516171819202122import numpy as npx = np.array([[1,2],[3,4],[5,6]])a = np.ones((x.shape[0],1))b = np.ones((1,x.shape[1]))c = np.hstack([x,a])d = np.vstack([x,b])print (a)print (b)print (c)print (d)[[ 1.] [ 1.] [ 1.]][[ 1. 1.]][[ 1. 2. 1.] [ 3. 4. 1.] [ 5. 6. 1.]][[ 1. 2.] [ 3. 4.] [ 5. 6.] [ 1. 1.]] h-horizontalv-vertical难以表达自行感受 numpy.random.randn(d0, d1, …, dn)其中d0, d1, …, dn为整数型，输出标准正太分布的矩阵。若想输出$N(\mu,\sigma^2)$则公式为：$\sigma$*np.random.randn(…)+$\mu$若我们要生成满足正太分布为N(3，2.5^2)，2行4列的数组，则2.5*np.random.randn(2, 4)+3输出12array([[-4.49401501, 4.00950034, -1.81814867, 7.29718677], [ 0.39924804, 4.68456316, 4.99394529, 4.84057254]]) svm_loss_naive()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def svm_loss_naive(W, X, y, reg): """ Structured SVM loss function, naive implementation (with loops). Inputs have dimension D, there are C classes, and we operate on minibatches of N examples. Inputs: - W: A numpy array of shape (D, C) containing weights. - X: A numpy array of shape (N, D) containing a minibatch of data. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - reg: (float) regularization strength Returns a tuple of: - loss as single float - gradient with respect to weights W; an array of same shape as W """ dW = np.zeros(W.shape) # initialize the gradient as zero # compute the loss and the gradient num_classes = W.shape[1] num_train = X.shape[0] loss = 0.0 for i in xrange(num_train): scores = X[i].dot(W) #scores包含10个类别的分数 correct_class_score = scores[y[i]] #正确类别下的分数 for j in xrange(num_classes): if j == y[i]: continue margin = scores[j] - correct_class_score + 1 # note delta = 1 if margin &gt; 0: loss += margin dW[:,y[i]] += X[i,:] dW[:,j] += -X[i,:] # Right now the loss is a sum over all training examples, but we want it # to be an average instead so we divide by num_train. loss /= num_train dW /= num_train # Add regularization to the loss. loss += 0.5 * reg * np.sum(W * W) dW += reg * W return loss, dW dW部分参考：梯度推导 梯度的抽样检测1234567891011121314151617181920def grad_check_sparse(f, x, analytic_grad, num_checks=10, h=1e-5): """ sample a few random elements and only return numerical in this dimensions. """ for i in xrange(num_checks): ix = tuple([randrange(m) for m in x.shape]) oldval = x[ix] x[ix] = oldval + h # increment by h fxph = f(x) # evaluate f(x + h) x[ix] = oldval - h # increment by h fxmh = f(x) # evaluate f(x - h) x[ix] = oldval # reset grad_numerical = (fxph - fxmh) / (2 * h) grad_analytic = analytic_grad[ix] rel_error = abs(grad_numerical - grad_analytic) / (abs(grad_numerical) + abs(grad_analytic)) print 'numerical: %f analytic: %f, relative error: %e' % (grad_numerical, grad_analytic, rel_error) 即判断$ \frac{f(x+h)-f(x-h)}{2h} = \frac{\partial f(x)}{\partial x} $ svm_loss_vectorized(W, X, y, reg)123456789101112131415161718192021222324def svm_loss_vectorized(W, X, y, reg): """ Structured SVM loss function, vectorized implementation.Inputs and outputs are the same as svm_loss_naive. """ loss = 0.0 dW = np.zeros(W.shape) # initialize the gradient as zero scores = X.dot(W) # num_train by num_class num_train = X.shape[0] num_classes = W.shape[1] scores_correct = scores[np.arange(num_train), y] # 1 by num_train #print scores_correct scores_correct = np.reshape(scores_correct, (num_train, 1)) # num_train by 1 margins = scores - scores_correct + 1.0 # num_train by num_class margins[np.arange(num_train), y] = 0.0 # 将正确标签下的margins置为0 margins[margins &lt;= 0] = 0.0 # 将值小于0的margins置为0 #print margins[0] loss += np.sum(margins) / num_train loss += 0.5 * reg * np.sum(W * W) # compute the gradient margins[margins &gt; 0] = 1.0 row_sum = np.sum(margins, axis=1) # 1 by num_train margins[np.arange(num_train), y] = -row_sum dW += np.dot(X.T, margins)/num_train + reg * W # dimension by num_class 关于loss就是将大于0的margins相加关于gradient即将margins中的数值分类。再通过最后一步 dW += np.dot(X.T, margins)/num_train + reg * W 完成梯度的计算。本质上与naive函数相同1234567 if margin &gt; 0: loss += margin dW[:,y[i]] += -X[i:] dW[:,j] += X[i:] dW /= num_traindW += reg * W PS:在linear_classifier.py中X的shape是D*N所以在一些地方要将X转置才行。]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231n学习笔记(KNN)]]></title>
    <url>%2F2017%2F05%2F22%2FCS231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[完成作业: [k_nearest_neighbor.py] [knn.ipynb] enumerate()12for y, cls in enumerate(classes): print y, cls enumerate能遍历一个数组或列表，并获得索引和索引内容。得到：123456789100 plane1 car2 bird3 cat4 deer5 dog6 frog7 horse8 ship9 truck flatnonzero()12idxs = np.flatnonzero(y_train == y)print idxs y_train 为训练集图片的标签集。flatnonzero() 打印非零元素的位置。整体意为以图片标签分类，输出图片的下标。12345678910[ 29 30 35 ..., 49941 49992 49994][ 4 5 32 ..., 49993 49998 49999][ 6 13 18 ..., 49987 49991 49995][ 9 17 21 ..., 49979 49982 49983][ 3 10 20 ..., 49981 49984 49990][ 27 40 51 ..., 49964 49980 49988][ 0 19 22 ..., 49962 49966 49996][ 7 11 12 ..., 49965 49978 49986][ 8 62 69 ..., 49968 49976 49985][ 1 2 14 ..., 49963 49971 49997] np.random.choice()官方介绍12idxs = np.random.choice(idxs, samples_per_class, replace=False) print idxs 从idxs中随机取出samples_per_class个数，不可重复。 subplot(m,n,p)1plt.subplot(samples_per_class, num_classes, plt_idx) subplot(m,n,p)是将多个图画到一个平面上的工具。其中，m表示是图排成m行，n表示图排成n列，也就是整个figure中有n个图是排成一行的，一共m行，如果m=2就是表示2行图。p表示图所在的位置，p=1表示从左到右从上到下的第一个位置。 reshape()1X_train = np.reshape(X_train, (X_train.shape[0], -1)) 如果newshape给的参数是（x,-1）,那么函数会自动判别newshape为(x, mn/x）,这里的x一定要能被m*n整除！stackoverflow有相关的介绍。‘-1’在此处的意义-1表示我懒得计算该填什么数字，让机器通过其他的值推测出来。 k_nearest_neighbor.py 作业12345678910111213for i in xrange(num_test): for j in xrange(num_train): ##################################################################### # TODO: # # Compute the l2 distance between the ith test point and the jth # # training point, and store the result in dists[i, j]. You should # # not use a loop over dimension. # ##################################################################### dists[i,j] = np.sum((X[i,:]-self.X_train[j,:])**2) ##################################################################### # END OF YOUR CODE # ##################################################################### return dists 这里代表X为测试集，X_train是训练集。X有500个点，每个点代表一张图片，有32*32维。每个点的维度都与训练集X_train相减后求平方的和。得到测试集与训练集的点的“距离”。 Inline Question #1: Notice the structured patterns in the distance matrix, where some rows or columns are visible brighter. (Note that with the default color scheme black indicates low distances while white indicates high distances.) What in the data is the cause behind the distinctly bright rows? What causes the columns?Your Answer: 明亮的行表示当前测试图与多数训练图相似度低，明亮的列表示当前训练图与多数测试图相似度低 argsort()返回的是数组值从小到大的索引值123x = np.array([3, 1, 2])np.argsort(x)array([1, 2, 0]) most_common()获取出现频率最高的s个字符1234567from collections import Counters = '''A Counter is a dict subclass for counting hashable objects. It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts. The Counter class is similar to bags or multisets in other languages.'''.lower()c = Counter(s)# 获取出现频率最高的5个字符print c.most_common(5)# Result:[(' ', 54), ('e', 32), ('s', 25), ('a', 24), ('t', 24)] numpy.linalg.norm(x, ord=None, axis=None, keepdims=False)官方解释ord表示求哪种范数，默认为L2范数。axis表示按照什么维度。0就是x轴，（0就是竖着比较，1就是横着比较。）具体看下面例子。12345678&gt;&gt;&gt; c = np.array([[ 1, 2, 3],... [-1, 1, 4]])&gt;&gt;&gt; LA.norm(c, axis=0)array([ 1.41421356, 2.23606798, 5. ])&gt;&gt;&gt; LA.norm(c, axis=1)array([ 3.74165739, 4.24264069])&gt;&gt;&gt; LA.norm(c, ord=1, axis=1)array([ 6., 6.]) numpy.ndarray.T矩阵的转置1234567&gt;&gt;&gt; x = np.array([[1.,2.],[3.,4.]])&gt;&gt;&gt; xarray([[ 1., 2.], [ 3., 4.]])&gt;&gt;&gt; x.Tarray([[ 1., 3.], [ 2., 4.]]) 作业 no-loops部分1234M = np.dot(X, self.X_train.T)te = np.square(X).sum(axis = 1)tr = np.square(self.X_train).sum(axis = 1)dists = np.sqrt(-2*M+tr+np.matrix(te).T) 利用(a-b)^2=a^2+b^2-2ab和numpy的broadcasting性质。]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssm架构下json数据传递问题和解决]]></title>
    <url>%2F2017%2F05%2F18%2Fssm%E6%9E%B6%E6%9E%84%E4%B8%8Bjson%E6%95%B0%E6%8D%AE%E4%BC%A0%E9%80%92%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[环境说明 springmvc-4.3.6 jar包 jackson-2.7.4 [jar]包 代码说明在springmvc.xml文件中采用&lt;mvc:annotation-driven/&gt;注解驱动。在jsp文件下,配置一个按钮调用下面的js代码12345678910function requestJson()&#123; $ajax(&#123; type:"post", url:"$&#123;pageContext.request.contextPath &#125;/requestJson.action", data:'&#123;"articleid":10,"title":"test"&#125;', success:function(data)&#123; alert(data); &#125; &#125;);&#125; 在后台创建一个controller。传入json数据，@RequestBody转为实体类。传出实体类，使用@ResponseBody转为json格式。1234567@Controllerpublic class JsonTest&#123; @RequestMapping("/requestJson") public @ResponseBody items requestJson(@RequestBody Items items)&#123; return items; &#125;&#125; 在浏览器中打开jsp页面，F12控制台观察requestJson.action的状态码 问题1.状态码200/415，不进入后端controller断点，浏览器弹出网页html代码解决办法：缺少class，更换jar包。 2.状态码400/500，不进入后端controller断点，浏览器无反应解决办法：jsp页面中data数据需采用正确的json编写格式，以逗号分隔。]]></content>
      <tags>
        <tag>spring mvc</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下使用hexo+github部署个人博客]]></title>
    <url>%2F2017%2F05%2F17%2F20170517%2F</url>
    <content type="text"><![CDATA[需要装好git, node.js 并全程科学上网(全局代理)。 使用gitbash npm install hexo 新建文件夹用于个人博客，并进入目录下hexo init 继续使用hexo g 和hexo s 生成并本地测试网站, 打开浏览器输入localhost:4000 ，此时需临时关闭全局代理方可看到本地博客。 配置config.yml文件(关键为deploy区域，其余部分自由发挥) 1234deploy: type: git repo: https://github.com/asdf0982/asdf0982.github.io.git branch: master 使用hexo d 将本地文档上传到github(需全局代理保证网络链接)如一切正常会弹出一个github登录框。关于ssh的配置，其实只是省略了这个登录的步骤。]]></content>
      <tags>
        <tag>git</tag>
        <tag>hexo</tag>
        <tag>windows</tag>
      </tags>
  </entry>
</search>